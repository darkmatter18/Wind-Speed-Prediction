{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Copyright 2020 Arkadip Bhattacharya\n",
    "\n",
    "#    Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#    you may not use this file except in compliance with the License.\n",
    "#    You may obtain a copy of the License at\n",
    "\n",
    "#        http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "#    Unless required by applicable law or agreed to in writing, software\n",
    "#    distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#    See the License for the specific language governing permissions and\n",
    "#    limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import dataloader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import Normalize_df, WindSpeedDataset, WindSpeedDatasetTimeSeries, ComposeTransform, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>air_temperature_mean</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370203</td>\n",
       "      <td>0.103164</td>\n",
       "      <td>0.732591</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.322799</td>\n",
       "      <td>0.268912</td>\n",
       "      <td>0.838440</td>\n",
       "      <td>0.354167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.302483</td>\n",
       "      <td>0.709078</td>\n",
       "      <td>0.988858</td>\n",
       "      <td>0.260417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.246050</td>\n",
       "      <td>0.850758</td>\n",
       "      <td>0.239554</td>\n",
       "      <td>0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.194131</td>\n",
       "      <td>0.827372</td>\n",
       "      <td>0.345404</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  air_temperature_mean  pressure  wind_direction  wind_speed\n",
       "0  0.000000              0.370203  0.103164        0.732591    0.625000\n",
       "1  0.000011              0.322799  0.268912        0.838440    0.354167\n",
       "2  0.000022              0.302483  0.709078        0.988858    0.260417\n",
       "3  0.000033              0.246050  0.850758        0.239554    0.093750\n",
       "4  0.000044              0.194131  0.827372        0.345404    0.291667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Normalize_df(pd.read_csv('./dataset-daily.csv'))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(dataset, test_size = 0.1)\n",
    "trainset, valset = train_test_split(trainset, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time                    0.885669\n",
       "air_temperature_mean    0.916479\n",
       "pressure                0.584593\n",
       "wind_direction          0.476323\n",
       "wind_speed              0.104167\n",
       "Name: 3145, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WindSpeedDatasetTimeSeries(trainset,transform=ComposeTransform([ToTensor()]))\n",
    "test_dataset = WindSpeedDatasetTimeSeries(testset, transform=ComposeTransform([ToTensor()]))\n",
    "val_dataset = WindSpeedDatasetTimeSeries(valset, transform=ComposeTransform([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9165, 0.5846, 0.4763],\n",
       "         [0.4221, 0.6527, 0.2730],\n",
       "         [0.6298, 0.5481, 0.6072],\n",
       "         [0.3657, 0.8205, 0.4903],\n",
       "         [0.3950, 0.3879, 0.4875],\n",
       "         [0.1174, 0.6334, 0.1253]], dtype=torch.float64), tensor([[0.1042],\n",
       "         [0.3021],\n",
       "         [0.2292],\n",
       "         [0.0833],\n",
       "         [0.2500],\n",
       "         [0.0417]], dtype=torch.float64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "trainloader = dataloader.DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "valloader = dataloader.DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "testloader = dataloader.DataLoader(test_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, l = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Count: 1\n",
      "Device: Tesla K80\n",
      "Device Capability: (3, 7)\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda') if cuda else torch.device('cpu')\n",
    "if cuda:\n",
    "    print(\"Device Count:\", torch.cuda.device_count())\n",
    "    print(\"Device:\", torch.cuda.get_device_name())\n",
    "    print(\"Device Capability:\", torch.cuda.get_device_capability())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (lstm1): LSTM(3, 100, batch_first=True)\n",
      "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (drop2): Dropout(p=0.2, inplace=False)\n",
      "  (fc3): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import Model\n",
    "model = Model(3, 100, 1, cuda=cuda)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 0 out of 93 Training Loss: 0.00012283050204797458 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 1 out of 93 Training Loss: 0.011517194330051382 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 2 out of 93 Training Loss: 0.02339511573995634 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 3 out of 93 Training Loss: 0.03372938581491991 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 4 out of 93 Training Loss: 0.04496961016888901 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 5 out of 93 Training Loss: 0.05738701601262375 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 6 out of 93 Training Loss: 0.06731593445624395 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 7 out of 93 Training Loss: 0.07635420956398531 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 8 out of 93 Training Loss: 0.08743429113860413 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 9 out of 93 Training Loss: 0.0990806336023955 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 10 out of 93 Training Loss: 0.10994193260307594 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 11 out of 93 Training Loss: 0.12054241378541275 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 12 out of 93 Training Loss: 0.13088304945017382 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 13 out of 93 Training Loss: 0.1395454418354778 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 14 out of 93 Training Loss: 0.15208265022124334 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 15 out of 93 Training Loss: 0.16393558983440681 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 16 out of 93 Training Loss: 0.17661106236959978 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 17 out of 93 Training Loss: 0.18614683788950726 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 18 out of 93 Training Loss: 0.19731289637024685 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 19 out of 93 Training Loss: 0.20858333003456875 Test Loss: 0.009840572337535295\n",
      "Epoch: 1 Batch: 20 out of 93 Training Loss: 0.0023556145794059943 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 21 out of 93 Training Loss: 0.013891163184430809 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 22 out of 93 Training Loss: 0.02478863847919962 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 23 out of 93 Training Loss: 0.03404493620165846 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 24 out of 93 Training Loss: 0.04476258893975279 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 25 out of 93 Training Loss: 0.0577625081829097 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 26 out of 93 Training Loss: 0.06930340164819024 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 27 out of 93 Training Loss: 0.08042002180137894 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 28 out of 93 Training Loss: 0.0894971684507396 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 29 out of 93 Training Loss: 0.10353457638540528 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 30 out of 93 Training Loss: 0.11444927183457873 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 31 out of 93 Training Loss: 0.12902093762078545 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 32 out of 93 Training Loss: 0.13751286724128983 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 33 out of 93 Training Loss: 0.14940274962702058 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 34 out of 93 Training Loss: 0.15861030285724662 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 35 out of 93 Training Loss: 0.16884477519908211 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 36 out of 93 Training Loss: 0.17957590324350856 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 37 out of 93 Training Loss: 0.19034498640814088 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 38 out of 93 Training Loss: 0.2039461656428244 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 39 out of 93 Training Loss: 0.2168320937968161 Test Loss: 0.0094048396514898\n",
      "Epoch: 1 Batch: 40 out of 93 Training Loss: 0.0024558555784958943 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 41 out of 93 Training Loss: 0.0135605445581812 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 42 out of 93 Training Loss: 0.026368633702709112 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 43 out of 93 Training Loss: 0.03684051786394302 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 44 out of 93 Training Loss: 0.048411929838671125 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 45 out of 93 Training Loss: 0.05861760475517694 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 46 out of 93 Training Loss: 0.06796707850725833 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 47 out of 93 Training Loss: 0.07748443153531734 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 48 out of 93 Training Loss: 0.08925334163786355 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 49 out of 93 Training Loss: 0.10070576038987819 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 50 out of 93 Training Loss: 0.11126053598554317 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 51 out of 93 Training Loss: 0.12138934791864339 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 52 out of 93 Training Loss: 0.13125690710575763 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 53 out of 93 Training Loss: 0.13984052636505548 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 54 out of 93 Training Loss: 0.14932274152369682 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 55 out of 93 Training Loss: 0.1601417370590705 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 56 out of 93 Training Loss: 0.16830092561276142 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 57 out of 93 Training Loss: 0.1803883452418584 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 58 out of 93 Training Loss: 0.19092839103968326 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 59 out of 93 Training Loss: 0.20037797265531007 Test Loss: 0.009124444289640947\n",
      "Epoch: 1 Batch: 60 out of 93 Training Loss: 0.002270812217269681 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 61 out of 93 Training Loss: 0.012194412808988832 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 62 out of 93 Training Loss: 0.025181191090617918 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 63 out of 93 Training Loss: 0.033932062845800665 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 64 out of 93 Training Loss: 0.042818334002171304 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 65 out of 93 Training Loss: 0.05220366739866569 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 66 out of 93 Training Loss: 0.061015513774131086 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 67 out of 93 Training Loss: 0.07236375850823953 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 68 out of 93 Training Loss: 0.08118263078120783 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 69 out of 93 Training Loss: 0.09287856989738777 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 70 out of 93 Training Loss: 0.10230966475990846 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 71 out of 93 Training Loss: 0.11221282468375995 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 72 out of 93 Training Loss: 0.12218949669239357 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 73 out of 93 Training Loss: 0.13205749546376302 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 74 out of 93 Training Loss: 0.14162476365653112 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 75 out of 93 Training Loss: 0.15162501116481855 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 76 out of 93 Training Loss: 0.16131317154702976 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 77 out of 93 Training Loss: 0.17144186799613073 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 78 out of 93 Training Loss: 0.1819736473747833 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 79 out of 93 Training Loss: 0.19185057659832075 Test Loss: 0.00854998877780004\n",
      "Epoch: 1 Batch: 80 out of 93 Training Loss: 0.0021728685992152283 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 81 out of 93 Training Loss: 0.01160458837918349 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 82 out of 93 Training Loss: 0.019796126422503668 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 83 out of 93 Training Loss: 0.02923957155368634 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 84 out of 93 Training Loss: 0.040203150262156206 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 85 out of 93 Training Loss: 0.049007124167898375 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 86 out of 93 Training Loss: 0.05794044760338374 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 87 out of 93 Training Loss: 0.06802551717779942 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 88 out of 93 Training Loss: 0.07927396324745722 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 89 out of 93 Training Loss: 0.08984622628710576 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 90 out of 93 Training Loss: 0.09927084659508773 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 91 out of 93 Training Loss: 0.10790857383332558 Test Loss: 0.008569105993956327\n",
      "Epoch: 1 Batch: 92 out of 93 Training Loss: 0.11884749391398736 Test Loss: 0.008569105993956327\n",
      "Epoch: 2 Batch: 0 out of 93 Training Loss: 0.00011196114643607088 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 1 out of 93 Training Loss: 0.010404240680477952 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 2 out of 93 Training Loss: 0.018773603593550063 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 3 out of 93 Training Loss: 0.02896162529065404 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 4 out of 93 Training Loss: 0.040998994713268615 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 5 out of 93 Training Loss: 0.049926802856467105 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 6 out of 93 Training Loss: 0.06060640920474324 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 7 out of 93 Training Loss: 0.06818235280512963 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 8 out of 93 Training Loss: 0.07860387476681863 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 9 out of 93 Training Loss: 0.08751533447354232 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 10 out of 93 Training Loss: 0.0978363555535594 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 11 out of 93 Training Loss: 0.10773772920071278 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 12 out of 93 Training Loss: 0.11875698516666089 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 13 out of 93 Training Loss: 0.12720234772711192 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 14 out of 93 Training Loss: 0.13652430369108115 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 15 out of 93 Training Loss: 0.1476676537334839 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 16 out of 93 Training Loss: 0.15524386741741691 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 17 out of 93 Training Loss: 0.16811737824752127 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 18 out of 93 Training Loss: 0.1780901861987928 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 19 out of 93 Training Loss: 0.18634411167874132 Test Loss: 0.008619997862049124\n",
      "Epoch: 2 Batch: 20 out of 93 Training Loss: 0.0020912444876486037 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 21 out of 93 Training Loss: 0.012551017730122207 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 22 out of 93 Training Loss: 0.02432303099948704 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 23 out of 93 Training Loss: 0.03480000856388152 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 24 out of 93 Training Loss: 0.04600555512178481 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 25 out of 93 Training Loss: 0.05767977765816987 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 26 out of 93 Training Loss: 0.06629548936206639 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 27 out of 93 Training Loss: 0.07650590284783185 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 28 out of 93 Training Loss: 0.08652405037600339 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 29 out of 93 Training Loss: 0.09602179999518931 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 30 out of 93 Training Loss: 0.10532355184722483 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 31 out of 93 Training Loss: 0.11342934860903561 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 32 out of 93 Training Loss: 0.12187446623164952 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 33 out of 93 Training Loss: 0.13126546206939757 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 34 out of 93 Training Loss: 0.14004600017387211 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 35 out of 93 Training Loss: 0.15065365533400119 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 36 out of 93 Training Loss: 0.160026674783414 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 37 out of 93 Training Loss: 0.17056839416790545 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 38 out of 93 Training Loss: 0.18040018684286416 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 39 out of 93 Training Loss: 0.189557461692577 Test Loss: 0.008692964572798122\n",
      "Epoch: 2 Batch: 40 out of 93 Training Loss: 0.0021406158130996265 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 41 out of 93 Training Loss: 0.011394452049993757 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 42 out of 93 Training Loss: 0.02224116095122028 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 43 out of 93 Training Loss: 0.0310784315016501 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 44 out of 93 Training Loss: 0.04064042840864587 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 45 out of 93 Training Loss: 0.050689769655131584 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 46 out of 93 Training Loss: 0.060357211835347896 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 47 out of 93 Training Loss: 0.0685509319674604 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 48 out of 93 Training Loss: 0.07844825249876905 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 49 out of 93 Training Loss: 0.08587548856403757 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 50 out of 93 Training Loss: 0.09338775391470719 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 51 out of 93 Training Loss: 0.10233582670580674 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 52 out of 93 Training Loss: 0.11281204058569003 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 53 out of 93 Training Loss: 0.12231881285797883 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 54 out of 93 Training Loss: 0.13122213653069068 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 55 out of 93 Training Loss: 0.14058509397100735 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 56 out of 93 Training Loss: 0.15072709156911898 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 57 out of 93 Training Loss: 0.15984122755717564 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 58 out of 93 Training Loss: 0.1708021613095336 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 59 out of 93 Training Loss: 0.17962493116747666 Test Loss: 0.008647260086780245\n",
      "Epoch: 2 Batch: 60 out of 93 Training Loss: 0.0020476859886844234 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 61 out of 93 Training Loss: 0.010616020381887682 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 62 out of 93 Training Loss: 0.019424386404891737 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 63 out of 93 Training Loss: 0.031631109387119535 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 64 out of 93 Training Loss: 0.03976246257170034 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 65 out of 93 Training Loss: 0.0486942744706471 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 66 out of 93 Training Loss: 0.05772786223187042 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 67 out of 93 Training Loss: 0.06859112166657043 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 68 out of 93 Training Loss: 0.07794898477240396 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 69 out of 93 Training Loss: 0.08747367662235093 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 70 out of 93 Training Loss: 0.09586778850152088 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 71 out of 93 Training Loss: 0.10571956363364053 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 72 out of 93 Training Loss: 0.11635273330702377 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 73 out of 93 Training Loss: 0.12491235797150922 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 74 out of 93 Training Loss: 0.13389969252838685 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 75 out of 93 Training Loss: 0.14316852399005486 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 76 out of 93 Training Loss: 0.15119383399232222 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 77 out of 93 Training Loss: 0.15992331606193377 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 78 out of 93 Training Loss: 0.16824792613132789 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 79 out of 93 Training Loss: 0.17655680336846902 Test Loss: 0.00884556444361806\n",
      "Epoch: 2 Batch: 80 out of 93 Training Loss: 0.0019960430389497435 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 81 out of 93 Training Loss: 0.012578229320630805 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 82 out of 93 Training Loss: 0.02359432344643809 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 83 out of 93 Training Loss: 0.03429624148963429 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 84 out of 93 Training Loss: 0.043321546067878976 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 85 out of 93 Training Loss: 0.05182419986783005 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 86 out of 93 Training Loss: 0.06017407578735091 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 87 out of 93 Training Loss: 0.07042742603777385 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 88 out of 93 Training Loss: 0.08001786460487581 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 89 out of 93 Training Loss: 0.08954890248684622 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 90 out of 93 Training Loss: 0.09816818022488094 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 91 out of 93 Training Loss: 0.10712631036846376 Test Loss: 0.008915575136515226\n",
      "Epoch: 2 Batch: 92 out of 93 Training Loss: 0.11726412446557022 Test Loss: 0.008915575136515226\n",
      "Epoch: 3 Batch: 0 out of 93 Training Loss: 0.00011307336590302888 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 1 out of 93 Training Loss: 0.009237850645697245 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 2 out of 93 Training Loss: 0.019550120087480673 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 3 out of 93 Training Loss: 0.0293379003202082 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 4 out of 93 Training Loss: 0.04014126174352182 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 5 out of 93 Training Loss: 0.05040325932405008 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 6 out of 93 Training Loss: 0.059400837497925886 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 7 out of 93 Training Loss: 0.06982004512301695 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 8 out of 93 Training Loss: 0.07940326035223019 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 9 out of 93 Training Loss: 0.08843805697015536 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 10 out of 93 Training Loss: 0.09846139848432553 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 11 out of 93 Training Loss: 0.10819139573923361 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 12 out of 93 Training Loss: 0.11549447579509628 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 13 out of 93 Training Loss: 0.125850958844787 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 14 out of 93 Training Loss: 0.13374565923786771 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 15 out of 93 Training Loss: 0.1430116259512962 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 16 out of 93 Training Loss: 0.15295828702128542 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 17 out of 93 Training Loss: 0.163841961046821 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 18 out of 93 Training Loss: 0.1725210352820815 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 19 out of 93 Training Loss: 0.18259780397838962 Test Loss: 0.008678417906842449\n",
      "Epoch: 3 Batch: 20 out of 93 Training Loss: 0.0020835550251802463 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 21 out of 93 Training Loss: 0.009871904433836605 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 22 out of 93 Training Loss: 0.019487907805611757 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 23 out of 93 Training Loss: 0.029737543941607145 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 24 out of 93 Training Loss: 0.039111222767402795 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 25 out of 93 Training Loss: 0.04741000912444797 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 26 out of 93 Training Loss: 0.05675604350226131 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 27 out of 93 Training Loss: 0.06742233845697847 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 28 out of 93 Training Loss: 0.07338968121739235 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 29 out of 93 Training Loss: 0.08177776743950453 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 30 out of 93 Training Loss: 0.09291848556431141 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 31 out of 93 Training Loss: 0.10071346552403775 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 32 out of 93 Training Loss: 0.10883286704601851 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 33 out of 93 Training Loss: 0.11757386491926518 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 34 out of 93 Training Loss: 0.12874794767530767 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 35 out of 93 Training Loss: 0.1394645768898925 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 36 out of 93 Training Loss: 0.15075117738278715 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 37 out of 93 Training Loss: 0.15880695839705078 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 38 out of 93 Training Loss: 0.16904406265648214 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 39 out of 93 Training Loss: 0.17915506025137512 Test Loss: 0.008742605293677612\n",
      "Epoch: 3 Batch: 40 out of 93 Training Loss: 0.002014432264403204 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 41 out of 93 Training Loss: 0.011600106185213427 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 42 out of 93 Training Loss: 0.02151937892092834 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 43 out of 93 Training Loss: 0.03198473544223676 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 44 out of 93 Training Loss: 0.041589225804344515 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 45 out of 93 Training Loss: 0.049509118473068575 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 46 out of 93 Training Loss: 0.05796368715716968 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 47 out of 93 Training Loss: 0.06681144439978967 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 48 out of 93 Training Loss: 0.07725130689694057 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 49 out of 93 Training Loss: 0.08538173341555963 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 50 out of 93 Training Loss: 0.09467827265514503 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 51 out of 93 Training Loss: 0.10529105474604736 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 52 out of 93 Training Loss: 0.11530028486056695 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 53 out of 93 Training Loss: 0.12597819154514442 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 54 out of 93 Training Loss: 0.1336473610009111 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 55 out of 93 Training Loss: 0.1421425772587813 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 56 out of 93 Training Loss: 0.15217254885836015 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 57 out of 93 Training Loss: 0.16324534376515518 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 58 out of 93 Training Loss: 0.17263560758335958 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 59 out of 93 Training Loss: 0.1826801646257795 Test Loss: 0.008806942750445822\n",
      "Epoch: 3 Batch: 60 out of 93 Training Loss: 0.0020726226608069106 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 61 out of 93 Training Loss: 0.010381698269656436 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 62 out of 93 Training Loss: 0.02047081723462655 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 63 out of 93 Training Loss: 0.02966310795049979 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 64 out of 93 Training Loss: 0.040392583828678864 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 65 out of 93 Training Loss: 0.04999649956475808 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 66 out of 93 Training Loss: 0.059122902933767575 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 67 out of 93 Training Loss: 0.06790569204490496 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 68 out of 93 Training Loss: 0.07585194859307123 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 69 out of 93 Training Loss: 0.085952615026644 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 70 out of 93 Training Loss: 0.09623083065848662 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 71 out of 93 Training Loss: 0.1052231263707192 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 72 out of 93 Training Loss: 0.11466896500091864 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 73 out of 93 Training Loss: 0.12282358914267136 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 74 out of 93 Training Loss: 0.13421579602759195 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 75 out of 93 Training Loss: 0.1478486327792318 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 76 out of 93 Training Loss: 0.1565836748446138 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 77 out of 93 Training Loss: 0.16453728884111954 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 78 out of 93 Training Loss: 0.17236599012862755 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 79 out of 93 Training Loss: 0.18094616349439932 Test Loss: 0.00881707173010165\n",
      "Epoch: 3 Batch: 80 out of 93 Training Loss: 0.0020597977327030527 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 81 out of 93 Training Loss: 0.011395681625775658 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 82 out of 93 Training Loss: 0.021739731519095265 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 83 out of 93 Training Loss: 0.029521706956050955 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 84 out of 93 Training Loss: 0.03980958599092778 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 85 out of 93 Training Loss: 0.046522544207594954 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 86 out of 93 Training Loss: 0.056737319076977336 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 87 out of 93 Training Loss: 0.06694499074908312 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 88 out of 93 Training Loss: 0.07922517831864175 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 89 out of 93 Training Loss: 0.08754283513369378 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 90 out of 93 Training Loss: 0.09690059020610865 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 91 out of 93 Training Loss: 0.10581590931358155 Test Loss: 0.008756076663055203\n",
      "Epoch: 3 Batch: 92 out of 93 Training Loss: 0.11469274710359391 Test Loss: 0.008756076663055203\n",
      "Epoch: 4 Batch: 0 out of 93 Training Loss: 9.239774437681322e-05 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 1 out of 93 Training Loss: 0.008121248635072862 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 2 out of 93 Training Loss: 0.0163480567956163 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 3 out of 93 Training Loss: 0.025876815731246623 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 4 out of 93 Training Loss: 0.03544457845630184 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 5 out of 93 Training Loss: 0.0441428491124703 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 6 out of 93 Training Loss: 0.052821389699895534 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 7 out of 93 Training Loss: 0.0627551193559362 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 8 out of 93 Training Loss: 0.07085917081924215 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 9 out of 93 Training Loss: 0.07888373576344981 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 10 out of 93 Training Loss: 0.08800807625295654 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 11 out of 93 Training Loss: 0.09707898304106727 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 12 out of 93 Training Loss: 0.10678025923909679 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 13 out of 93 Training Loss: 0.11522194400670066 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 14 out of 93 Training Loss: 0.12423891604187026 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 15 out of 93 Training Loss: 0.13292693376781478 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 16 out of 93 Training Loss: 0.14351548936458364 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 17 out of 93 Training Loss: 0.15185445204617515 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 18 out of 93 Training Loss: 0.160322678575833 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 19 out of 93 Training Loss: 0.17101980030776992 Test Loss: 0.008586374958130446\n",
      "Epoch: 4 Batch: 20 out of 93 Training Loss: 0.001978667155735161 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 21 out of 93 Training Loss: 0.009875418321125175 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 22 out of 93 Training Loss: 0.018786703870527412 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 23 out of 93 Training Loss: 0.028121527918510105 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 24 out of 93 Training Loss: 0.03834534499876943 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 25 out of 93 Training Loss: 0.04913979180239883 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 26 out of 93 Training Loss: 0.05605015361764279 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 27 out of 93 Training Loss: 0.06561310978689042 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 28 out of 93 Training Loss: 0.07507236691274491 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 29 out of 93 Training Loss: 0.0856964282513484 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 30 out of 93 Training Loss: 0.09583691803821173 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 31 out of 93 Training Loss: 0.10450533328660574 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 32 out of 93 Training Loss: 0.11453378403642026 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 33 out of 93 Training Loss: 0.12386143503793326 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 34 out of 93 Training Loss: 0.13212701415725794 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 35 out of 93 Training Loss: 0.14176267588593808 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 36 out of 93 Training Loss: 0.1502975879059061 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 37 out of 93 Training Loss: 0.1592009506941661 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 38 out of 93 Training Loss: 0.16802523301997033 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 39 out of 93 Training Loss: 0.17681631369598952 Test Loss: 0.008884487038647587\n",
      "Epoch: 4 Batch: 40 out of 93 Training Loss: 0.0019920381024488673 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 41 out of 93 Training Loss: 0.008838934940845655 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 42 out of 93 Training Loss: 0.017837434192747758 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 43 out of 93 Training Loss: 0.03119280759766786 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 44 out of 93 Training Loss: 0.03944691654816358 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 45 out of 93 Training Loss: 0.0487585450761029 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 46 out of 93 Training Loss: 0.057485247147829224 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 47 out of 93 Training Loss: 0.06746252917274921 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 48 out of 93 Training Loss: 0.07640924409553497 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 49 out of 93 Training Loss: 0.08597867016270845 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 50 out of 93 Training Loss: 0.09698805038407533 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 51 out of 93 Training Loss: 0.10568462044522255 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 52 out of 93 Training Loss: 0.11628361151143997 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 53 out of 93 Training Loss: 0.1270683855988094 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 54 out of 93 Training Loss: 0.13550136901959864 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 55 out of 93 Training Loss: 0.14581701171174732 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 56 out of 93 Training Loss: 0.1563046762026855 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 57 out of 93 Training Loss: 0.16463201225325552 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 58 out of 93 Training Loss: 0.1738429722614595 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 59 out of 93 Training Loss: 0.18346960574910132 Test Loss: 0.00875150149857456\n",
      "Epoch: 4 Batch: 60 out of 93 Training Loss: 0.00205700970831258 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 61 out of 93 Training Loss: 0.011694162484434674 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 62 out of 93 Training Loss: 0.02021726067754371 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 63 out of 93 Training Loss: 0.030218328681019375 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 64 out of 93 Training Loss: 0.03876611064764602 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 65 out of 93 Training Loss: 0.04566515503096325 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 66 out of 93 Training Loss: 0.055204249784526656 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 67 out of 93 Training Loss: 0.06483085346984607 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 68 out of 93 Training Loss: 0.07233675136807305 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 69 out of 93 Training Loss: 0.08185168575140578 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 70 out of 93 Training Loss: 0.09416256598773343 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 71 out of 93 Training Loss: 0.10252392511459929 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 72 out of 93 Training Loss: 0.11228482178988797 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 73 out of 93 Training Loss: 0.12295792098733527 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 74 out of 93 Training Loss: 0.13301860294881207 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 75 out of 93 Training Loss: 0.14353272352012736 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 76 out of 93 Training Loss: 0.15156091969105345 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 77 out of 93 Training Loss: 0.16112115360441548 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 78 out of 93 Training Loss: 0.17157140127959591 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 79 out of 93 Training Loss: 0.18158363584074122 Test Loss: 0.008775733919306234\n",
      "Epoch: 4 Batch: 80 out of 93 Training Loss: 0.002061156509506098 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 81 out of 93 Training Loss: 0.011686536436962477 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 82 out of 93 Training Loss: 0.0214763273951286 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 83 out of 93 Training Loss: 0.03234825837432086 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 84 out of 93 Training Loss: 0.042382602533387534 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 85 out of 93 Training Loss: 0.05126380450098454 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 86 out of 93 Training Loss: 0.061122078402029864 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 87 out of 93 Training Loss: 0.07024673460988938 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 88 out of 93 Training Loss: 0.0791090670508021 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 89 out of 93 Training Loss: 0.08949233121244847 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 90 out of 93 Training Loss: 0.10008290032862364 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 91 out of 93 Training Loss: 0.10812812387018143 Test Loss: 0.00866246104917743\n",
      "Epoch: 4 Batch: 92 out of 93 Training Loss: 0.12148496690212428 Test Loss: 0.00866246104917743\n",
      "Epoch: 5 Batch: 0 out of 93 Training Loss: 9.137656419507919e-05 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 1 out of 93 Training Loss: 0.010872630252232474 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 2 out of 93 Training Loss: 0.019269164501418988 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 3 out of 93 Training Loss: 0.02948684509723417 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 4 out of 93 Training Loss: 0.03975784577309124 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 5 out of 93 Training Loss: 0.049286612159302155 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 6 out of 93 Training Loss: 0.058270444943299214 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 7 out of 93 Training Loss: 0.06927265677480929 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 8 out of 93 Training Loss: 0.07797301545619004 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 9 out of 93 Training Loss: 0.0857414136069917 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 10 out of 93 Training Loss: 0.0941699369239711 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 11 out of 93 Training Loss: 0.10311276450633042 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 12 out of 93 Training Loss: 0.11293247885881894 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 13 out of 93 Training Loss: 0.12232641953854792 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 14 out of 93 Training Loss: 0.1308317033934497 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 15 out of 93 Training Loss: 0.14203916381924384 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 16 out of 93 Training Loss: 0.15101801216482155 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 17 out of 93 Training Loss: 0.15889493267863028 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 18 out of 93 Training Loss: 0.16855917762844794 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 19 out of 93 Training Loss: 0.17627773186071746 Test Loss: 0.008789890361103144\n",
      "Epoch: 5 Batch: 20 out of 93 Training Loss: 0.001995567015449423 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 21 out of 93 Training Loss: 0.010445098175744433 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 22 out of 93 Training Loss: 0.022821103937069792 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 23 out of 93 Training Loss: 0.031194531141857523 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 24 out of 93 Training Loss: 0.040927730283777136 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 25 out of 93 Training Loss: 0.04880404916320266 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 26 out of 93 Training Loss: 0.05953273341719331 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 27 out of 93 Training Loss: 0.06923478820089521 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 28 out of 93 Training Loss: 0.07880397584948959 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 29 out of 93 Training Loss: 0.08834364336643638 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 30 out of 93 Training Loss: 0.09841069929961385 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 31 out of 93 Training Loss: 0.10812821869466724 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 32 out of 93 Training Loss: 0.11640689220939102 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 33 out of 93 Training Loss: 0.1248456377229494 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 34 out of 93 Training Loss: 0.13524719585392894 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 35 out of 93 Training Loss: 0.1433684395319623 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 36 out of 93 Training Loss: 0.15218346451137485 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 37 out of 93 Training Loss: 0.1596414374812347 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 38 out of 93 Training Loss: 0.16792572221447052 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 39 out of 93 Training Loss: 0.17720569881338896 Test Loss: 0.008629877712916244\n",
      "Epoch: 5 Batch: 40 out of 93 Training Loss: 0.002015860403448132 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 41 out of 93 Training Loss: 0.012377015898495701 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 42 out of 93 Training Loss: 0.021513314569860484 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 43 out of 93 Training Loss: 0.029713648954897906 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 44 out of 93 Training Loss: 0.03948756551977971 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 45 out of 93 Training Loss: 0.048551923247545745 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 46 out of 93 Training Loss: 0.057214300731688525 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 47 out of 93 Training Loss: 0.06780456064876893 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 48 out of 93 Training Loss: 0.0778289219611583 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 49 out of 93 Training Loss: 0.08600488735970833 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 50 out of 93 Training Loss: 0.09645887429502585 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 51 out of 93 Training Loss: 0.10598221107062676 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 52 out of 93 Training Loss: 0.11629367771235087 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 53 out of 93 Training Loss: 0.12588493398067335 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 54 out of 93 Training Loss: 0.13488922233369927 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 55 out of 93 Training Loss: 0.14353751542654614 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 56 out of 93 Training Loss: 0.1535205660634933 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 57 out of 93 Training Loss: 0.1643940327936111 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 58 out of 93 Training Loss: 0.17425276863065342 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 59 out of 93 Training Loss: 0.1834304524832664 Test Loss: 0.008677927988835356\n",
      "Epoch: 5 Batch: 60 out of 93 Training Loss: 0.002072763214934575 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 61 out of 93 Training Loss: 0.011135018947649705 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 62 out of 93 Training Loss: 0.019011715944040525 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 63 out of 93 Training Loss: 0.02827738184027742 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 64 out of 93 Training Loss: 0.03784479997598003 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 65 out of 93 Training Loss: 0.04659901704185079 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 66 out of 93 Training Loss: 0.05481994576298069 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 67 out of 93 Training Loss: 0.06407324742071699 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 68 out of 93 Training Loss: 0.07118342961661886 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 69 out of 93 Training Loss: 0.07863486656465005 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 70 out of 93 Training Loss: 0.08807554287381839 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 71 out of 93 Training Loss: 0.09702054136909913 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 72 out of 93 Training Loss: 0.104272455494035 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 73 out of 93 Training Loss: 0.11231334093504022 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 74 out of 93 Training Loss: 0.12094287253462147 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 75 out of 93 Training Loss: 0.1307694321080334 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 76 out of 93 Training Loss: 0.13983867741667103 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 77 out of 93 Training Loss: 0.15106378826789926 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 78 out of 93 Training Loss: 0.16015162370644878 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 79 out of 93 Training Loss: 0.1702135741292722 Test Loss: 0.008554048285904255\n",
      "Epoch: 5 Batch: 80 out of 93 Training Loss: 0.0019217917791289744 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 81 out of 93 Training Loss: 0.011326012397436564 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 82 out of 93 Training Loss: 0.019992580833165116 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 83 out of 93 Training Loss: 0.027328909104941554 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 84 out of 93 Training Loss: 0.0381416508092267 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 85 out of 93 Training Loss: 0.04795553415107555 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 86 out of 93 Training Loss: 0.0586152511744482 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 87 out of 93 Training Loss: 0.06793983439940042 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 88 out of 93 Training Loss: 0.07741625207501478 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 89 out of 93 Training Loss: 0.08761502402859754 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 90 out of 93 Training Loss: 0.0967124409137947 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 91 out of 93 Training Loss: 0.10666976469594068 Test Loss: 0.008477119898254221\n",
      "Epoch: 5 Batch: 92 out of 93 Training Loss: 0.1168635009883625 Test Loss: 0.008477119898254221\n",
      "Epoch: 6 Batch: 0 out of 93 Training Loss: 9.342498316239285e-05 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 1 out of 93 Training Loss: 0.010136850468654146 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 2 out of 93 Training Loss: 0.02152956306173276 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 3 out of 93 Training Loss: 0.030384161799985876 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 4 out of 93 Training Loss: 0.03877010877414416 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 5 out of 93 Training Loss: 0.04717226634903621 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 6 out of 93 Training Loss: 0.056061109818357935 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 7 out of 93 Training Loss: 0.06385916500522565 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 8 out of 93 Training Loss: 0.07150315336121987 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 9 out of 93 Training Loss: 0.0822509017883129 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 10 out of 93 Training Loss: 0.09001496509819101 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 11 out of 93 Training Loss: 0.10058303159831833 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 12 out of 93 Training Loss: 0.1102026885485537 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 13 out of 93 Training Loss: 0.11852353141813349 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 14 out of 93 Training Loss: 0.1302821541315205 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 15 out of 93 Training Loss: 0.13994751387445997 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 16 out of 93 Training Loss: 0.14769868628292154 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 17 out of 93 Training Loss: 0.15623263717799257 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 18 out of 93 Training Loss: 0.16603358724324774 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 19 out of 93 Training Loss: 0.17614586447535824 Test Loss: 0.008687634486705065\n",
      "Epoch: 6 Batch: 20 out of 93 Training Loss: 0.002014154997041669 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 21 out of 93 Training Loss: 0.010319010783305611 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 22 out of 93 Training Loss: 0.021343497056832757 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 23 out of 93 Training Loss: 0.03130252143399998 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 24 out of 93 Training Loss: 0.04193479796903416 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 25 out of 93 Training Loss: 0.05055374415623232 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 26 out of 93 Training Loss: 0.05882880507068917 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 27 out of 93 Training Loss: 0.06896751696275755 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 28 out of 93 Training Loss: 0.07759198216753288 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 29 out of 93 Training Loss: 0.08670916264908596 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 30 out of 93 Training Loss: 0.09710590491103216 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 31 out of 93 Training Loss: 0.10491502001913472 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 32 out of 93 Training Loss: 0.11435016520353242 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 33 out of 93 Training Loss: 0.123089302294275 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 34 out of 93 Training Loss: 0.13272197447749062 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 35 out of 93 Training Loss: 0.14115451179476662 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 36 out of 93 Training Loss: 0.15216919589819594 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 37 out of 93 Training Loss: 0.16251905724438115 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 38 out of 93 Training Loss: 0.17216719497027083 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 39 out of 93 Training Loss: 0.1810848852250187 Test Loss: 0.008400248109617016\n",
      "Epoch: 6 Batch: 40 out of 93 Training Loss: 0.0020318352463138665 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 41 out of 93 Training Loss: 0.010388309586275872 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 42 out of 93 Training Loss: 0.02000144075923091 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 43 out of 93 Training Loss: 0.029967664259899912 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 44 out of 93 Training Loss: 0.038157302405167876 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 45 out of 93 Training Loss: 0.04872293256544 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 46 out of 93 Training Loss: 0.05737383522414094 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 47 out of 93 Training Loss: 0.06798881803028708 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 48 out of 93 Training Loss: 0.07746240262262946 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 49 out of 93 Training Loss: 0.08671831664018756 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 50 out of 93 Training Loss: 0.09629549596779471 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 51 out of 93 Training Loss: 0.10471683133714324 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 52 out of 93 Training Loss: 0.11372803569160825 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 53 out of 93 Training Loss: 0.12294974688761359 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 54 out of 93 Training Loss: 0.13220928654395467 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 55 out of 93 Training Loss: 0.1406203633951438 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 56 out of 93 Training Loss: 0.1493915957244528 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 57 out of 93 Training Loss: 0.15941636402480727 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 58 out of 93 Training Loss: 0.1692912285061968 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 59 out of 93 Training Loss: 0.1784538910570038 Test Loss: 0.008606692183424126\n",
      "Epoch: 6 Batch: 60 out of 93 Training Loss: 0.002004028262745194 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 61 out of 93 Training Loss: 0.012723309884022526 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 62 out of 93 Training Loss: 0.02169715982134228 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 63 out of 93 Training Loss: 0.031073496641765883 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 64 out of 93 Training Loss: 0.03985965062136536 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 65 out of 93 Training Loss: 0.04963720679486876 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 66 out of 93 Training Loss: 0.05855244580860024 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 67 out of 93 Training Loss: 0.06827722020650988 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 68 out of 93 Training Loss: 0.07701152187044506 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 69 out of 93 Training Loss: 0.08525227379257565 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 70 out of 93 Training Loss: 0.09372679792548304 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 71 out of 93 Training Loss: 0.10277910154516583 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 72 out of 93 Training Loss: 0.11402701117302065 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 73 out of 93 Training Loss: 0.12404465485567932 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 74 out of 93 Training Loss: 0.1340645700340975 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 75 out of 93 Training Loss: 0.141937037894677 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 76 out of 93 Training Loss: 0.15107219569588787 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 77 out of 93 Training Loss: 0.1601203996335972 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 78 out of 93 Training Loss: 0.16796438485587722 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 79 out of 93 Training Loss: 0.17510199450160152 Test Loss: 0.008418592243370685\n",
      "Epoch: 6 Batch: 80 out of 93 Training Loss: 0.001999947011733043 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 81 out of 93 Training Loss: 0.011537286222243297 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 82 out of 93 Training Loss: 0.019505031176173675 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 83 out of 93 Training Loss: 0.027418321699166286 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 84 out of 93 Training Loss: 0.036141723163688175 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 85 out of 93 Training Loss: 0.04494551453020572 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 86 out of 93 Training Loss: 0.054453573890292636 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 87 out of 93 Training Loss: 0.06390290963675975 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 88 out of 93 Training Loss: 0.07592146075543164 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 89 out of 93 Training Loss: 0.08682974311735629 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 90 out of 93 Training Loss: 0.09926906763788461 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 91 out of 93 Training Loss: 0.10712419706609248 Test Loss: 0.008640056983991102\n",
      "Epoch: 6 Batch: 92 out of 93 Training Loss: 0.11615399713840484 Test Loss: 0.008640056983991102\n",
      "Epoch: 7 Batch: 0 out of 93 Training Loss: 9.343422628859038e-05 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 1 out of 93 Training Loss: 0.00944875668413857 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 2 out of 93 Training Loss: 0.019278127920403273 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 3 out of 93 Training Loss: 0.02723290793277243 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 4 out of 93 Training Loss: 0.03853626850671986 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 5 out of 93 Training Loss: 0.04833809494651774 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 6 out of 93 Training Loss: 0.05803162533469418 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 7 out of 93 Training Loss: 0.06712409130908469 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 8 out of 93 Training Loss: 0.07596321239747027 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 9 out of 93 Training Loss: 0.08487300317414025 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 10 out of 93 Training Loss: 0.09204620098374704 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 11 out of 93 Training Loss: 0.101827596068903 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 12 out of 93 Training Loss: 0.11238034510664562 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 13 out of 93 Training Loss: 0.12114289192162374 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 14 out of 93 Training Loss: 0.13030532257310967 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 15 out of 93 Training Loss: 0.13894909595750193 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 16 out of 93 Training Loss: 0.14786045228741984 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 17 out of 93 Training Loss: 0.1582521039401732 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 18 out of 93 Training Loss: 0.16664267493091445 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 19 out of 93 Training Loss: 0.17484756348334174 Test Loss: 0.008686940524388443\n",
      "Epoch: 7 Batch: 20 out of 93 Training Loss: 0.001975063562398788 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 21 out of 93 Training Loss: 0.010422936968510982 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 22 out of 93 Training Loss: 0.02026883918047511 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 23 out of 93 Training Loss: 0.029326559372251863 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 24 out of 93 Training Loss: 0.0392586648017224 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 25 out of 93 Training Loss: 0.04899209304899537 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 26 out of 93 Training Loss: 0.05785821038485133 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 27 out of 93 Training Loss: 0.06759168147296274 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 28 out of 93 Training Loss: 0.07761752265692318 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 29 out of 93 Training Loss: 0.08658273644000852 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 30 out of 93 Training Loss: 0.09584098714590633 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 31 out of 93 Training Loss: 0.1044281826838907 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 32 out of 93 Training Loss: 0.11444602846354807 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 33 out of 93 Training Loss: 0.12503077029437387 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 34 out of 93 Training Loss: 0.13324158205837572 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 35 out of 93 Training Loss: 0.1417821313738879 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 36 out of 93 Training Loss: 0.15323821581155622 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 37 out of 93 Training Loss: 0.1619004210010227 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 38 out of 93 Training Loss: 0.17149800374359453 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 39 out of 93 Training Loss: 0.1803938563466128 Test Loss: 0.008710417049852285\n",
      "Epoch: 7 Batch: 40 out of 93 Training Loss: 0.002013587927145403 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 41 out of 93 Training Loss: 0.0092103249148256 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 42 out of 93 Training Loss: 0.018974931979251545 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 43 out of 93 Training Loss: 0.028095125289333504 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 44 out of 93 Training Loss: 0.037718589486253895 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 45 out of 93 Training Loss: 0.046892911264372505 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 46 out of 93 Training Loss: 0.05645263481296364 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 47 out of 93 Training Loss: 0.06502972829498116 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 48 out of 93 Training Loss: 0.07296053699560229 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 49 out of 93 Training Loss: 0.0813839091674215 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 50 out of 93 Training Loss: 0.09055649868555132 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 51 out of 93 Training Loss: 0.09989758028991286 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 52 out of 93 Training Loss: 0.10863239604390923 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 53 out of 93 Training Loss: 0.11514595111243192 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 54 out of 93 Training Loss: 0.12469994888983432 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 55 out of 93 Training Loss: 0.13396790211431447 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 56 out of 93 Training Loss: 0.14339146071456138 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 57 out of 93 Training Loss: 0.15419706662527982 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 58 out of 93 Training Loss: 0.1653183806442446 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 59 out of 93 Training Loss: 0.1762382616975135 Test Loss: 0.008570860055359926\n",
      "Epoch: 7 Batch: 60 out of 93 Training Loss: 0.001993475477598502 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 61 out of 93 Training Loss: 0.009995944793723418 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 62 out of 93 Training Loss: 0.01977495383044322 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 63 out of 93 Training Loss: 0.029692385341428117 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 64 out of 93 Training Loss: 0.03916870150288184 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 65 out of 93 Training Loss: 0.04889046866019805 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 66 out of 93 Training Loss: 0.05823903623541434 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 67 out of 93 Training Loss: 0.06687099579294761 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 68 out of 93 Training Loss: 0.07488124444653829 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 69 out of 93 Training Loss: 0.08469743653704961 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 70 out of 93 Training Loss: 0.09582538995464882 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 71 out of 93 Training Loss: 0.10460517555048307 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 72 out of 93 Training Loss: 0.11330659780224403 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 73 out of 93 Training Loss: 0.12141039687713226 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 74 out of 93 Training Loss: 0.12958599254062017 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 75 out of 93 Training Loss: 0.1409385455729588 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 76 out of 93 Training Loss: 0.15133365615775426 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 77 out of 93 Training Loss: 0.16118032391687473 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 78 out of 93 Training Loss: 0.1698108557569011 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 79 out of 93 Training Loss: 0.1772667020516618 Test Loss: 0.00869149308313023\n",
      "Epoch: 7 Batch: 80 out of 93 Training Loss: 0.0019964119819565317 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 81 out of 93 Training Loss: 0.011927309486047795 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 82 out of 93 Training Loss: 0.018523874732629828 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 83 out of 93 Training Loss: 0.026525003875569872 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 84 out of 93 Training Loss: 0.03501137629427152 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 85 out of 93 Training Loss: 0.042771187650935225 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 86 out of 93 Training Loss: 0.05168981388487058 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 87 out of 93 Training Loss: 0.06320357140429454 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 88 out of 93 Training Loss: 0.07376854405082899 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 89 out of 93 Training Loss: 0.08291096616812187 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 90 out of 93 Training Loss: 0.09129074871815877 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 91 out of 93 Training Loss: 0.10116472658045726 Test Loss: 0.008497008588165045\n",
      "Epoch: 7 Batch: 92 out of 93 Training Loss: 0.11261912904955583 Test Loss: 0.008497008588165045\n",
      "Epoch: 8 Batch: 0 out of 93 Training Loss: 0.00010046105511406416 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 1 out of 93 Training Loss: 0.009612296928241048 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 2 out of 93 Training Loss: 0.017964264598264487 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 3 out of 93 Training Loss: 0.02783986761845568 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 4 out of 93 Training Loss: 0.036988404799773486 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 5 out of 93 Training Loss: 0.04292366256616929 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 6 out of 93 Training Loss: 0.051813487649484666 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 7 out of 93 Training Loss: 0.06181178217433313 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 8 out of 93 Training Loss: 0.07080761318705896 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 9 out of 93 Training Loss: 0.07955753499321559 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 10 out of 93 Training Loss: 0.08985910633258441 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 11 out of 93 Training Loss: 0.0999756397088609 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 12 out of 93 Training Loss: 0.10906405536137441 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 13 out of 93 Training Loss: 0.11836108261398891 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 14 out of 93 Training Loss: 0.12752364085666756 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 15 out of 93 Training Loss: 0.13528207339025955 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 16 out of 93 Training Loss: 0.1447296060962222 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 17 out of 93 Training Loss: 0.1537499131975315 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 18 out of 93 Training Loss: 0.1648013528776906 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 19 out of 93 Training Loss: 0.17403160243906002 Test Loss: 0.008569149342788891\n",
      "Epoch: 8 Batch: 20 out of 93 Training Loss: 0.001965383520736 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 21 out of 93 Training Loss: 0.011876570513858101 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 22 out of 93 Training Loss: 0.020481281435503266 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 23 out of 93 Training Loss: 0.03001534984113147 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 24 out of 93 Training Loss: 0.0378280687019365 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 25 out of 93 Training Loss: 0.04592425048948695 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 26 out of 93 Training Loss: 0.053505662816031474 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 27 out of 93 Training Loss: 0.06410381289796402 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 28 out of 93 Training Loss: 0.07103419349194934 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 29 out of 93 Training Loss: 0.0802186946258085 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 30 out of 93 Training Loss: 0.08900934130550792 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 31 out of 93 Training Loss: 0.09786984649152924 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 32 out of 93 Training Loss: 0.1082689496562021 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 33 out of 93 Training Loss: 0.11924927354456355 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 34 out of 93 Training Loss: 0.12798916128130128 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 35 out of 93 Training Loss: 0.13641074531377723 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 36 out of 93 Training Loss: 0.14585553620608022 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 37 out of 93 Training Loss: 0.15546207175256183 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 38 out of 93 Training Loss: 0.16469616115690638 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 39 out of 93 Training Loss: 0.17456137899906804 Test Loss: 0.008558396885002201\n",
      "Epoch: 8 Batch: 40 out of 93 Training Loss: 0.0019812691124217667 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 41 out of 93 Training Loss: 0.01072853292395045 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 42 out of 93 Training Loss: 0.01987141511459519 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 43 out of 93 Training Loss: 0.030480562253488795 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 44 out of 93 Training Loss: 0.0390365491719978 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 45 out of 93 Training Loss: 0.04803813668955733 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 46 out of 93 Training Loss: 0.05808853871245553 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 47 out of 93 Training Loss: 0.0670825378136771 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 48 out of 93 Training Loss: 0.0777587886067169 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 49 out of 93 Training Loss: 0.08625208820272853 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 50 out of 93 Training Loss: 0.0963225527765291 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 51 out of 93 Training Loss: 0.10709590232987573 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 52 out of 93 Training Loss: 0.11653229641784599 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 53 out of 93 Training Loss: 0.12576664286722114 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 54 out of 93 Training Loss: 0.13397467463333776 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 55 out of 93 Training Loss: 0.1412707772204714 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 56 out of 93 Training Loss: 0.14879998705406358 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 57 out of 93 Training Loss: 0.158050319655432 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 58 out of 93 Training Loss: 0.1673849676834481 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 59 out of 93 Training Loss: 0.17678496382255723 Test Loss: 0.008358832956715063\n",
      "Epoch: 8 Batch: 60 out of 93 Training Loss: 0.0020005700019279015 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 61 out of 93 Training Loss: 0.011283174793151905 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 62 out of 93 Training Loss: 0.019623381721703102 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 63 out of 93 Training Loss: 0.029170440214602043 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 64 out of 93 Training Loss: 0.03884496789696603 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 65 out of 93 Training Loss: 0.05002311867001443 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 66 out of 93 Training Loss: 0.05817668669196754 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 67 out of 93 Training Loss: 0.06768996425244003 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 68 out of 93 Training Loss: 0.0755705299628058 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 69 out of 93 Training Loss: 0.08469558850201755 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 70 out of 93 Training Loss: 0.0928757103932181 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 71 out of 93 Training Loss: 0.10207562957230001 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 72 out of 93 Training Loss: 0.10956806427138835 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 73 out of 93 Training Loss: 0.11949166672575265 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 74 out of 93 Training Loss: 0.12780344968932658 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 75 out of 93 Training Loss: 0.13658195564794332 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 76 out of 93 Training Loss: 0.14586841238933593 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 77 out of 93 Training Loss: 0.155197212642906 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 78 out of 93 Training Loss: 0.1647572090690115 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 79 out of 93 Training Loss: 0.17505619412559062 Test Loss: 0.008615900085053661\n",
      "Epoch: 8 Batch: 80 out of 93 Training Loss: 0.001991364095309066 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 81 out of 93 Training Loss: 0.010718218903937624 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 82 out of 93 Training Loss: 0.020467253323593424 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 83 out of 93 Training Loss: 0.02898659642408161 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 84 out of 93 Training Loss: 0.037515801299312396 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 85 out of 93 Training Loss: 0.047121027406254096 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 86 out of 93 Training Loss: 0.055409180853464884 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 87 out of 93 Training Loss: 0.06379024955997734 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 88 out of 93 Training Loss: 0.07410185310611991 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 89 out of 93 Training Loss: 0.0830066464058545 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 90 out of 93 Training Loss: 0.09161529775331287 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 91 out of 93 Training Loss: 0.10206752635160951 Test Loss: 0.008672443133863535\n",
      "Epoch: 8 Batch: 92 out of 93 Training Loss: 0.10763054426381855 Test Loss: 0.008672443133863535\n",
      "Epoch: 9 Batch: 0 out of 93 Training Loss: 0.00011330293191056097 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 1 out of 93 Training Loss: 0.009781907402699994 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 2 out of 93 Training Loss: 0.019593896434432077 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 3 out of 93 Training Loss: 0.027416521773463296 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 4 out of 93 Training Loss: 0.03507499219549279 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 5 out of 93 Training Loss: 0.04456156873775105 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 6 out of 93 Training Loss: 0.05691965585274081 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 7 out of 93 Training Loss: 0.06459199133959989 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 8 out of 93 Training Loss: 0.07366180009839515 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 9 out of 93 Training Loss: 0.08250014539507608 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 10 out of 93 Training Loss: 0.09252770207521896 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 11 out of 93 Training Loss: 0.10339385606048088 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 12 out of 93 Training Loss: 0.11131359878627042 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 13 out of 93 Training Loss: 0.1207605363771079 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 14 out of 93 Training Loss: 0.12931558172849397 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 15 out of 93 Training Loss: 0.1387178633332012 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 16 out of 93 Training Loss: 0.14855194892433862 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 17 out of 93 Training Loss: 0.15717875174877624 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 18 out of 93 Training Loss: 0.1653687167882679 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 19 out of 93 Training Loss: 0.17359818387476186 Test Loss: 0.00867045031521808\n",
      "Epoch: 9 Batch: 20 out of 93 Training Loss: 0.0019499325373397698 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 21 out of 93 Training Loss: 0.009780128597580038 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 22 out of 93 Training Loss: 0.01706246949668988 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 23 out of 93 Training Loss: 0.02399849576812252 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 24 out of 93 Training Loss: 0.0332539078028129 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 25 out of 93 Training Loss: 0.04332803154300913 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 26 out of 93 Training Loss: 0.05162423534255489 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 27 out of 93 Training Loss: 0.060433914530389155 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 28 out of 93 Training Loss: 0.06988195853244528 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 29 out of 93 Training Loss: 0.07759189244296416 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 30 out of 93 Training Loss: 0.08707097183849677 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 31 out of 93 Training Loss: 0.09617124509003028 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 32 out of 93 Training Loss: 0.10582795377757415 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 33 out of 93 Training Loss: 0.11478824272688493 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 34 out of 93 Training Loss: 0.12435171391751632 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 35 out of 93 Training Loss: 0.13421791151102647 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 36 out of 93 Training Loss: 0.14292246673192843 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 37 out of 93 Training Loss: 0.1522763949998842 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 38 out of 93 Training Loss: 0.16107975609537228 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 39 out of 93 Training Loss: 0.17039373714413508 Test Loss: 0.008754845793274317\n",
      "Epoch: 9 Batch: 40 out of 93 Training Loss: 0.001920807957642423 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 41 out of 93 Training Loss: 0.011048120297484743 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 42 out of 93 Training Loss: 0.019555278904729235 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 43 out of 93 Training Loss: 0.027427452467375147 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 44 out of 93 Training Loss: 0.03740565463899885 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 45 out of 93 Training Loss: 0.04618401903658424 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 46 out of 93 Training Loss: 0.05459337759762321 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 47 out of 93 Training Loss: 0.0634728081896833 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 48 out of 93 Training Loss: 0.07103473352267657 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 49 out of 93 Training Loss: 0.07994301555677567 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 50 out of 93 Training Loss: 0.08609200347214256 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 51 out of 93 Training Loss: 0.09623448163270269 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 52 out of 93 Training Loss: 0.1055546736717156 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 53 out of 93 Training Loss: 0.1122535316646031 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 54 out of 93 Training Loss: 0.12243886370211159 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 55 out of 93 Training Loss: 0.13245368920265949 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 56 out of 93 Training Loss: 0.14164956737309015 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 57 out of 93 Training Loss: 0.15159880448132074 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 58 out of 93 Training Loss: 0.16098754838108337 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 59 out of 93 Training Loss: 0.17021109335123813 Test Loss: 0.00872829861261628\n",
      "Epoch: 9 Batch: 60 out of 93 Training Loss: 0.0019374740424174686 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 61 out of 93 Training Loss: 0.009610087529065075 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 62 out of 93 Training Loss: 0.017797669314088285 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 63 out of 93 Training Loss: 0.026783444836975992 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 64 out of 93 Training Loss: 0.0366918834971804 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 65 out of 93 Training Loss: 0.04724596712017244 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 66 out of 93 Training Loss: 0.05753750904673523 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 67 out of 93 Training Loss: 0.06836465831124967 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 68 out of 93 Training Loss: 0.07714488814795202 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 69 out of 93 Training Loss: 0.08690950452560371 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 70 out of 93 Training Loss: 0.09726659293496794 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 71 out of 93 Training Loss: 0.10670984155708736 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 72 out of 93 Training Loss: 0.11583884517872518 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 73 out of 93 Training Loss: 0.12570481739217226 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 74 out of 93 Training Loss: 0.13489218886220639 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 75 out of 93 Training Loss: 0.1447197617145795 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 76 out of 93 Training Loss: 0.15361119612330382 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 77 out of 93 Training Loss: 0.16406804408157055 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 78 out of 93 Training Loss: 0.17353061764711325 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 79 out of 93 Training Loss: 0.18141240804666464 Test Loss: 0.00855068853971633\n",
      "Epoch: 9 Batch: 80 out of 93 Training Loss: 0.002047252820386701 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 81 out of 93 Training Loss: 0.010311841012491994 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 82 out of 93 Training Loss: 0.018744399750187213 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 83 out of 93 Training Loss: 0.02870999460811835 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 84 out of 93 Training Loss: 0.0399956228002451 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 85 out of 93 Training Loss: 0.05044509282107573 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 86 out of 93 Training Loss: 0.05971560159470063 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 87 out of 93 Training Loss: 0.06932421771581393 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 88 out of 93 Training Loss: 0.07960656283195239 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 89 out of 93 Training Loss: 0.08990649597491246 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 90 out of 93 Training Loss: 0.0985997924372099 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 91 out of 93 Training Loss: 0.10979741437132579 Test Loss: 0.008583429523489693\n",
      "Epoch: 9 Batch: 92 out of 93 Training Loss: 0.11777366881962043 Test Loss: 0.008583429523489693\n",
      "Epoch: 10 Batch: 0 out of 93 Training Loss: 0.00011460556178003229 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 1 out of 93 Training Loss: 0.008041145079719123 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 2 out of 93 Training Loss: 0.018090041154014167 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 3 out of 93 Training Loss: 0.028223150209473667 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 4 out of 93 Training Loss: 0.03799782300828605 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 5 out of 93 Training Loss: 0.04647241885303169 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 6 out of 93 Training Loss: 0.05519237256138235 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 7 out of 93 Training Loss: 0.06301532013802438 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 8 out of 93 Training Loss: 0.07223396448879152 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 9 out of 93 Training Loss: 0.08163714388846069 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 10 out of 93 Training Loss: 0.08939543672366648 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 11 out of 93 Training Loss: 0.09870288920118123 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 12 out of 93 Training Loss: 0.10773979433341532 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 13 out of 93 Training Loss: 0.11689589106007128 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 14 out of 93 Training Loss: 0.12701444261236697 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 15 out of 93 Training Loss: 0.13580859572155982 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 16 out of 93 Training Loss: 0.1438465661229065 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 17 out of 93 Training Loss: 0.15257979490323573 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 18 out of 93 Training Loss: 0.1627169589371851 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 19 out of 93 Training Loss: 0.16998231204687267 Test Loss: 0.008705277038230137\n",
      "Epoch: 10 Batch: 20 out of 93 Training Loss: 0.0019385625476573006 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 21 out of 93 Training Loss: 0.010259712753686716 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 22 out of 93 Training Loss: 0.019388455605003643 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 23 out of 93 Training Loss: 0.027235281361136246 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 24 out of 93 Training Loss: 0.03534600668201189 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 25 out of 93 Training Loss: 0.0441196045706604 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 26 out of 93 Training Loss: 0.054323021961245346 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 27 out of 93 Training Loss: 0.06354106281498413 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 28 out of 93 Training Loss: 0.07347841531584005 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 29 out of 93 Training Loss: 0.08202070806721191 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 30 out of 93 Training Loss: 0.0905266233588193 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 31 out of 93 Training Loss: 0.10070316277990084 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 32 out of 93 Training Loss: 0.10898456506976824 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 33 out of 93 Training Loss: 0.1196764537001584 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 34 out of 93 Training Loss: 0.13028382294425706 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 35 out of 93 Training Loss: 0.13904004514763096 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 36 out of 93 Training Loss: 0.14812573109367827 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 37 out of 93 Training Loss: 0.15835327346423606 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 38 out of 93 Training Loss: 0.16702641517469624 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 39 out of 93 Training Loss: 0.17587457940528134 Test Loss: 0.00847971820357171\n",
      "Epoch: 10 Batch: 40 out of 93 Training Loss: 0.0019793116946800783 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 41 out of 93 Training Loss: 0.011440891539035662 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 42 out of 93 Training Loss: 0.01868554786714755 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 43 out of 93 Training Loss: 0.02781755407276593 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 44 out of 93 Training Loss: 0.03645429131510697 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 45 out of 93 Training Loss: 0.04542738408717356 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 46 out of 93 Training Loss: 0.056426235706834416 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 47 out of 93 Training Loss: 0.06560505204769812 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 48 out of 93 Training Loss: 0.07657915097597084 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 49 out of 93 Training Loss: 0.08538062800589047 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 50 out of 93 Training Loss: 0.09517660015198431 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 51 out of 93 Training Loss: 0.10303580691042385 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 52 out of 93 Training Loss: 0.11508012493076764 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 53 out of 93 Training Loss: 0.1248433480498477 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 54 out of 93 Training Loss: 0.1327314854127451 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 55 out of 93 Training Loss: 0.14246997260424338 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 56 out of 93 Training Loss: 0.15117049612971983 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 57 out of 93 Training Loss: 0.1614880331319853 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 58 out of 93 Training Loss: 0.16964467079314433 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 59 out of 93 Training Loss: 0.17897762288275204 Test Loss: 0.008618299595334313\n",
      "Epoch: 10 Batch: 60 out of 93 Training Loss: 0.0020164483081560455 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 61 out of 93 Training Loss: 0.010725600537286314 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 62 out of 93 Training Loss: 0.02139708482138923 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 63 out of 93 Training Loss: 0.028572180666403088 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 64 out of 93 Training Loss: 0.03782288207151106 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 65 out of 93 Training Loss: 0.04670077877529076 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 66 out of 93 Training Loss: 0.05558613723553828 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 67 out of 93 Training Loss: 0.06474430988021306 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 68 out of 93 Training Loss: 0.07384430746026448 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 69 out of 93 Training Loss: 0.08283428883589915 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 70 out of 93 Training Loss: 0.09341174399890116 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 71 out of 93 Training Loss: 0.10162463540621212 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 72 out of 93 Training Loss: 0.11036032287813834 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 73 out of 93 Training Loss: 0.11899412645436934 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 74 out of 93 Training Loss: 0.12924444431848936 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 75 out of 93 Training Loss: 0.13865722006596737 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 76 out of 93 Training Loss: 0.14949686861075573 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 77 out of 93 Training Loss: 0.15816382447667532 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 78 out of 93 Training Loss: 0.16905828694291525 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 79 out of 93 Training Loss: 0.17821135966517143 Test Loss: 0.00856476179747419\n",
      "Epoch: 10 Batch: 80 out of 93 Training Loss: 0.0020080135612918926 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 81 out of 93 Training Loss: 0.010079777933581073 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 82 out of 93 Training Loss: 0.0172838220781817 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 83 out of 93 Training Loss: 0.025652191270066696 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 84 out of 93 Training Loss: 0.034313496801926094 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 85 out of 93 Training Loss: 0.0424166290498509 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 86 out of 93 Training Loss: 0.05304097816712995 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 87 out of 93 Training Loss: 0.06222430304057737 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 88 out of 93 Training Loss: 0.06983066643021842 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 89 out of 93 Training Loss: 0.08139267018429776 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 90 out of 93 Training Loss: 0.09058574321113368 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 91 out of 93 Training Loss: 0.09935678368799229 Test Loss: 0.008679490197788586\n",
      "Epoch: 10 Batch: 92 out of 93 Training Loss: 0.10774133367828866 Test Loss: 0.008679490197788586\n",
      "Epoch: 11 Batch: 0 out of 93 Training Loss: 9.845265297479527e-05 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 1 out of 93 Training Loss: 0.0086360953107316 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 2 out of 93 Training Loss: 0.016613564203663538 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 3 out of 93 Training Loss: 0.0242459613188941 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 4 out of 93 Training Loss: 0.03240514521597214 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 5 out of 93 Training Loss: 0.04083563455490656 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 6 out of 93 Training Loss: 0.050018982711418344 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 7 out of 93 Training Loss: 0.05720846935285516 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 8 out of 93 Training Loss: 0.06627705901040025 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 9 out of 93 Training Loss: 0.07565790343208499 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 10 out of 93 Training Loss: 0.08588939926697202 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 11 out of 93 Training Loss: 0.0952688187651176 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 12 out of 93 Training Loss: 0.10258996787591167 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 13 out of 93 Training Loss: 0.11322641673608012 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 14 out of 93 Training Loss: 0.12074060526786633 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 15 out of 93 Training Loss: 0.13102181230781862 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 16 out of 93 Training Loss: 0.14013776810018608 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 17 out of 93 Training Loss: 0.14906555389164278 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 18 out of 93 Training Loss: 0.1573570591687996 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 19 out of 93 Training Loss: 0.1665788858488042 Test Loss: 0.008547135290097107\n",
      "Epoch: 11 Batch: 20 out of 93 Training Loss: 0.0018710891679248063 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 21 out of 93 Training Loss: 0.012010031096669121 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 22 out of 93 Training Loss: 0.02066870564225523 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 23 out of 93 Training Loss: 0.02866985993090479 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 24 out of 93 Training Loss: 0.03747243126484959 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 25 out of 93 Training Loss: 0.04688473762574999 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 26 out of 93 Training Loss: 0.05773559929433672 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 27 out of 93 Training Loss: 0.06602800050381033 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 28 out of 93 Training Loss: 0.07489875582608788 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 29 out of 93 Training Loss: 0.08407761687043516 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 30 out of 93 Training Loss: 0.09419776377830116 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 31 out of 93 Training Loss: 0.10457241506877749 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 32 out of 93 Training Loss: 0.11307806586477367 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 33 out of 93 Training Loss: 0.12151269400122969 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 34 out of 93 Training Loss: 0.131615563944014 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 35 out of 93 Training Loss: 0.14070720569792597 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 36 out of 93 Training Loss: 0.1491983185485324 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 37 out of 93 Training Loss: 0.15932486923042147 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 38 out of 93 Training Loss: 0.16614091507721154 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 39 out of 93 Training Loss: 0.1742875987626931 Test Loss: 0.008643139407716015\n",
      "Epoch: 11 Batch: 40 out of 93 Training Loss: 0.001993009972756931 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 41 out of 93 Training Loss: 0.010460345226710865 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 42 out of 93 Training Loss: 0.018732705305701324 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 43 out of 93 Training Loss: 0.029084054905360767 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 44 out of 93 Training Loss: 0.039758402075058055 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 45 out of 93 Training Loss: 0.0476413314821182 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 46 out of 93 Training Loss: 0.055402331206387115 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 47 out of 93 Training Loss: 0.06458806261736734 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 48 out of 93 Training Loss: 0.07406262323576791 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 49 out of 93 Training Loss: 0.08477302655894144 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 50 out of 93 Training Loss: 0.09321287755239589 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 51 out of 93 Training Loss: 0.10089518377873881 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 52 out of 93 Training Loss: 0.1106291726822017 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 53 out of 93 Training Loss: 0.12222207213137133 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 54 out of 93 Training Loss: 0.13046439333204013 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 55 out of 93 Training Loss: 0.1395480294371007 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 56 out of 93 Training Loss: 0.15004361296389085 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 57 out of 93 Training Loss: 0.15937322998735887 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 58 out of 93 Training Loss: 0.16772369543406945 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 59 out of 93 Training Loss: 0.1767236717635749 Test Loss: 0.008592216382649813\n",
      "Epoch: 11 Batch: 60 out of 93 Training Loss: 0.001975157870594594 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 61 out of 93 Training Loss: 0.012428561797980402 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 62 out of 93 Training Loss: 0.02131154166037235 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 63 out of 93 Training Loss: 0.029946365034822557 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 64 out of 93 Training Loss: 0.03899221458906326 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 65 out of 93 Training Loss: 0.05157312621796522 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 66 out of 93 Training Loss: 0.06182160099471006 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 67 out of 93 Training Loss: 0.06942092498267088 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 68 out of 93 Training Loss: 0.07797733285898362 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 69 out of 93 Training Loss: 0.08740819116557036 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 70 out of 93 Training Loss: 0.09571282902235184 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 71 out of 93 Training Loss: 0.10543540177369509 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 72 out of 93 Training Loss: 0.11577925515795146 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 73 out of 93 Training Loss: 0.12464547493929062 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 74 out of 93 Training Loss: 0.13400943262005244 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 75 out of 93 Training Loss: 0.14323742372417841 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 76 out of 93 Training Loss: 0.15215731376284752 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 77 out of 93 Training Loss: 0.16248819196099434 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 78 out of 93 Training Loss: 0.1731928704443017 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 79 out of 93 Training Loss: 0.18195383866751585 Test Loss: 0.00845595978369767\n",
      "Epoch: 11 Batch: 80 out of 93 Training Loss: 0.0020588573069848463 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 81 out of 93 Training Loss: 0.009981486201433127 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 82 out of 93 Training Loss: 0.017953289859143677 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 83 out of 93 Training Loss: 0.027168230340031567 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 84 out of 93 Training Loss: 0.03645875696107525 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 85 out of 93 Training Loss: 0.045964154601243916 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 86 out of 93 Training Loss: 0.05582860782757181 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 87 out of 93 Training Loss: 0.06298456126838703 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 88 out of 93 Training Loss: 0.07320819115280885 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 89 out of 93 Training Loss: 0.08190452000140924 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 90 out of 93 Training Loss: 0.09154773568749208 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 91 out of 93 Training Loss: 0.09916370799779672 Test Loss: 0.00838723960755901\n",
      "Epoch: 11 Batch: 92 out of 93 Training Loss: 0.10642743594959159 Test Loss: 0.00838723960755901\n",
      "Epoch: 12 Batch: 0 out of 93 Training Loss: 0.00011476825281817426 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 1 out of 93 Training Loss: 0.00969690966710288 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 2 out of 93 Training Loss: 0.018581310727743692 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 3 out of 93 Training Loss: 0.02660455226257283 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 4 out of 93 Training Loss: 0.03444264035031039 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 5 out of 93 Training Loss: 0.042972129278926435 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 6 out of 93 Training Loss: 0.05195192198559481 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 7 out of 93 Training Loss: 0.0596572402614339 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 8 out of 93 Training Loss: 0.06820268181443054 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 9 out of 93 Training Loss: 0.07646526952564556 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 10 out of 93 Training Loss: 0.08555835017293531 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 11 out of 93 Training Loss: 0.09454439577936966 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 12 out of 93 Training Loss: 0.10492965949058372 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 13 out of 93 Training Loss: 0.11287464478343565 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 14 out of 93 Training Loss: 0.12005075949534613 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 15 out of 93 Training Loss: 0.13023327335074383 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 16 out of 93 Training Loss: 0.1394013962458058 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 17 out of 93 Training Loss: 0.1475433599884792 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 18 out of 93 Training Loss: 0.15576791900500495 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 19 out of 93 Training Loss: 0.1665887576277538 Test Loss: 0.008564367551695217\n",
      "Epoch: 12 Batch: 20 out of 93 Training Loss: 0.0018958174921283625 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 21 out of 93 Training Loss: 0.011059557583154193 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 22 out of 93 Training Loss: 0.019834939885855666 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 23 out of 93 Training Loss: 0.029960667278588763 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 24 out of 93 Training Loss: 0.03957853702080344 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 25 out of 93 Training Loss: 0.04881585904580449 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 26 out of 93 Training Loss: 0.057570357371092784 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 27 out of 93 Training Loss: 0.06763576672595834 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 28 out of 93 Training Loss: 0.07757021163773631 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 29 out of 93 Training Loss: 0.08762779695165251 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 30 out of 93 Training Loss: 0.09603538693112229 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 31 out of 93 Training Loss: 0.1052197539545307 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 32 out of 93 Training Loss: 0.11310830854994153 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 33 out of 93 Training Loss: 0.12179744106900786 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 34 out of 93 Training Loss: 0.1294776620641062 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 35 out of 93 Training Loss: 0.13838804609325622 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 36 out of 93 Training Loss: 0.14831732589003538 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 37 out of 93 Training Loss: 0.15616720638421272 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 38 out of 93 Training Loss: 0.16400693639364933 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 39 out of 93 Training Loss: 0.17177515899014567 Test Loss: 0.008695962838828564\n",
      "Epoch: 12 Batch: 40 out of 93 Training Loss: 0.0019251574835466541 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 41 out of 93 Training Loss: 0.010153402674822728 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 42 out of 93 Training Loss: 0.018432146038739602 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 43 out of 93 Training Loss: 0.026797514509289185 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 44 out of 93 Training Loss: 0.03523254032048456 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 45 out of 93 Training Loss: 0.0443882598614978 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 46 out of 93 Training Loss: 0.05427270392688982 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 47 out of 93 Training Loss: 0.06553151934209339 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 48 out of 93 Training Loss: 0.07568707885953657 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 49 out of 93 Training Loss: 0.08446648540708296 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 50 out of 93 Training Loss: 0.0926266816517996 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 51 out of 93 Training Loss: 0.10093905507388584 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 52 out of 93 Training Loss: 0.11013416024657957 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 53 out of 93 Training Loss: 0.11840499481919281 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 54 out of 93 Training Loss: 0.12782306792947523 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 55 out of 93 Training Loss: 0.13640642455580704 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 56 out of 93 Training Loss: 0.14528644933166973 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 57 out of 93 Training Loss: 0.1546840780487942 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 58 out of 93 Training Loss: 0.16245864108937852 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 59 out of 93 Training Loss: 0.17261149418341987 Test Loss: 0.008621423928575083\n",
      "Epoch: 12 Batch: 60 out of 93 Training Loss: 0.001939895193381642 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 61 out of 93 Training Loss: 0.011200558024747703 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 62 out of 93 Training Loss: 0.01898872815380845 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 63 out of 93 Training Loss: 0.028017076294226978 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 64 out of 93 Training Loss: 0.03700003177235875 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 65 out of 93 Training Loss: 0.046404332484407756 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 66 out of 93 Training Loss: 0.05419174218858633 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 67 out of 93 Training Loss: 0.06281510470743332 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 68 out of 93 Training Loss: 0.07492495151544962 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 69 out of 93 Training Loss: 0.08407527776743326 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 70 out of 93 Training Loss: 0.09382485607947263 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 71 out of 93 Training Loss: 0.10393875753815326 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 72 out of 93 Training Loss: 0.11238118084455881 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 73 out of 93 Training Loss: 0.11952741500298533 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 74 out of 93 Training Loss: 0.12872136533568654 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 75 out of 93 Training Loss: 0.13771292716573033 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 76 out of 93 Training Loss: 0.14541802099282894 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 77 out of 93 Training Loss: 0.15440677116001997 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 78 out of 93 Training Loss: 0.16582134468789253 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 79 out of 93 Training Loss: 0.1760442909815446 Test Loss: 0.008545393928546797\n",
      "Epoch: 12 Batch: 80 out of 93 Training Loss: 0.0019931970074383324 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 81 out of 93 Training Loss: 0.011437604194840582 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 82 out of 93 Training Loss: 0.021559206759890707 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 83 out of 93 Training Loss: 0.03352514001574197 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 84 out of 93 Training Loss: 0.04275244566645303 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 85 out of 93 Training Loss: 0.053291840469798235 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 86 out of 93 Training Loss: 0.062136256127020506 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 87 out of 93 Training Loss: 0.07091557885553518 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 88 out of 93 Training Loss: 0.07977739720638671 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 89 out of 93 Training Loss: 0.08910345750894227 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 90 out of 93 Training Loss: 0.09821866731192747 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 91 out of 93 Training Loss: 0.10839497483368793 Test Loss: 0.008582270915874025\n",
      "Epoch: 12 Batch: 92 out of 93 Training Loss: 0.11760629526372829 Test Loss: 0.008582270915874025\n",
      "Epoch: 13 Batch: 0 out of 93 Training Loss: 0.000104020590022687 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 1 out of 93 Training Loss: 0.009514346959129456 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 2 out of 93 Training Loss: 0.017586988637283925 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 3 out of 93 Training Loss: 0.027292285354868058 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 4 out of 93 Training Loss: 0.036117115298346165 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 5 out of 93 Training Loss: 0.047250801006392125 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 6 out of 93 Training Loss: 0.05446970579965461 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 7 out of 93 Training Loss: 0.06480290205968964 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 8 out of 93 Training Loss: 0.07364205946965563 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 9 out of 93 Training Loss: 0.08331603860302317 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 10 out of 93 Training Loss: 0.09265758400602686 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 11 out of 93 Training Loss: 0.10200498277141201 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 12 out of 93 Training Loss: 0.11128129368467676 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 13 out of 93 Training Loss: 0.11999263172788965 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 14 out of 93 Training Loss: 0.12916626432730305 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 15 out of 93 Training Loss: 0.13825820596708405 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 16 out of 93 Training Loss: 0.14805779257608997 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 17 out of 93 Training Loss: 0.15755291214032519 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 18 out of 93 Training Loss: 0.16655658954574215 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 19 out of 93 Training Loss: 0.1757493235711609 Test Loss: 0.008751934013244781\n",
      "Epoch: 13 Batch: 20 out of 93 Training Loss: 0.001989899776576192 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 21 out of 93 Training Loss: 0.011066117897329957 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 22 out of 93 Training Loss: 0.02213848439574066 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 23 out of 93 Training Loss: 0.03187774644762102 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 24 out of 93 Training Loss: 0.041228529639242326 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 25 out of 93 Training Loss: 0.04963980393081728 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 26 out of 93 Training Loss: 0.058243435449598466 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 27 out of 93 Training Loss: 0.0664875354763848 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 28 out of 93 Training Loss: 0.07437420786887232 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 29 out of 93 Training Loss: 0.08146248116686765 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 30 out of 93 Training Loss: 0.08920854946195904 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 31 out of 93 Training Loss: 0.09854487573325459 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 32 out of 93 Training Loss: 0.10669785981595341 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 33 out of 93 Training Loss: 0.115100804358421 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 34 out of 93 Training Loss: 0.12336001975059334 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 35 out of 93 Training Loss: 0.13052848038792436 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 36 out of 93 Training Loss: 0.13954320327907627 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 37 out of 93 Training Loss: 0.14814668485492294 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 38 out of 93 Training Loss: 0.15702197851210659 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 39 out of 93 Training Loss: 0.16526023355841463 Test Loss: 0.008609135719862852\n",
      "Epoch: 13 Batch: 40 out of 93 Training Loss: 0.001875311332681468 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 41 out of 93 Training Loss: 0.012476150142886928 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 42 out of 93 Training Loss: 0.020723998743036084 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 43 out of 93 Training Loss: 0.0305750856277731 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 44 out of 93 Training Loss: 0.04015624915335446 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 45 out of 93 Training Loss: 0.05128296949986487 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 46 out of 93 Training Loss: 0.05999247376892834 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 47 out of 93 Training Loss: 0.07018419561062127 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 48 out of 93 Training Loss: 0.07851975803349286 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 49 out of 93 Training Loss: 0.08722021450374394 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 50 out of 93 Training Loss: 0.09638282769445448 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 51 out of 93 Training Loss: 0.1055890938368824 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 52 out of 93 Training Loss: 0.11495248620484143 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 53 out of 93 Training Loss: 0.12290290297094851 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 54 out of 93 Training Loss: 0.1339268853989628 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 55 out of 93 Training Loss: 0.14394888394598038 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 56 out of 93 Training Loss: 0.15342931096527845 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 57 out of 93 Training Loss: 0.16240294297311575 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 58 out of 93 Training Loss: 0.1720615012672928 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 59 out of 93 Training Loss: 0.18268771396104366 Test Loss: 0.00865020759573037\n",
      "Epoch: 13 Batch: 60 out of 93 Training Loss: 0.002086059322629978 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 61 out of 93 Training Loss: 0.012161878069912006 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 62 out of 93 Training Loss: 0.019684554675643257 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 63 out of 93 Training Loss: 0.029062087314252666 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 64 out of 93 Training Loss: 0.03765368800801497 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 65 out of 93 Training Loss: 0.04737034034175139 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 66 out of 93 Training Loss: 0.05617068674606543 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 67 out of 93 Training Loss: 0.06322128152665954 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 68 out of 93 Training Loss: 0.07209009783533674 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 69 out of 93 Training Loss: 0.08260021465090375 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 70 out of 93 Training Loss: 0.09061059368965488 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 71 out of 93 Training Loss: 0.09862078646389108 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 72 out of 93 Training Loss: 0.10591935239923458 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 73 out of 93 Training Loss: 0.11495804753345709 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 74 out of 93 Training Loss: 0.12431350130779009 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 75 out of 93 Training Loss: 0.13341292612445813 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 76 out of 93 Training Loss: 0.14434854839188319 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 77 out of 93 Training Loss: 0.15462502990109186 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 78 out of 93 Training Loss: 0.16335175153059225 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 79 out of 93 Training Loss: 0.1732286481578396 Test Loss: 0.008591571653431112\n",
      "Epoch: 13 Batch: 80 out of 93 Training Loss: 0.001951657592549809 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 81 out of 93 Training Loss: 0.01057823503692437 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 82 out of 93 Training Loss: 0.01869954670150567 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 83 out of 93 Training Loss: 0.027245892568722258 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 84 out of 93 Training Loss: 0.03521561192651082 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 85 out of 93 Training Loss: 0.04270439584110666 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 86 out of 93 Training Loss: 0.04951280298013974 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 87 out of 93 Training Loss: 0.05982831342448283 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 88 out of 93 Training Loss: 0.06786795554985095 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 89 out of 93 Training Loss: 0.07544729940895725 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 90 out of 93 Training Loss: 0.08389973070774961 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 91 out of 93 Training Loss: 0.09316060494934011 Test Loss: 0.008599625096063723\n",
      "Epoch: 13 Batch: 92 out of 93 Training Loss: 0.10034465406392504 Test Loss: 0.008599625096063723\n",
      "Epoch: 14 Batch: 0 out of 93 Training Loss: 9.134675185847026e-05 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 1 out of 93 Training Loss: 0.008309926677455184 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 2 out of 93 Training Loss: 0.017241922046949146 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 3 out of 93 Training Loss: 0.027379609484185455 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 4 out of 93 Training Loss: 0.035406880851794956 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 5 out of 93 Training Loss: 0.044671750467230556 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 6 out of 93 Training Loss: 0.05265410507838893 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 7 out of 93 Training Loss: 0.06169123745333123 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 8 out of 93 Training Loss: 0.07093014831464457 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 9 out of 93 Training Loss: 0.07969250141452718 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 10 out of 93 Training Loss: 0.0895040340981977 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 11 out of 93 Training Loss: 0.09750235530357527 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 12 out of 93 Training Loss: 0.10537261872362065 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 13 out of 93 Training Loss: 0.11425834598760772 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 14 out of 93 Training Loss: 0.12472359261285233 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 15 out of 93 Training Loss: 0.13278631104897426 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 16 out of 93 Training Loss: 0.14070984518896507 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 17 out of 93 Training Loss: 0.14979212249438928 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 18 out of 93 Training Loss: 0.1608474867678778 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 19 out of 93 Training Loss: 0.17000782566886113 Test Loss: 0.008530182425271381\n",
      "Epoch: 14 Batch: 20 out of 93 Training Loss: 0.0019150204258335712 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 21 out of 93 Training Loss: 0.010116894287086833 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 22 out of 93 Training Loss: 0.019174021226383557 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 23 out of 93 Training Loss: 0.02737198446414601 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 24 out of 93 Training Loss: 0.036636970494903436 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 25 out of 93 Training Loss: 0.04543555669955145 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 26 out of 93 Training Loss: 0.054235212993837704 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 27 out of 93 Training Loss: 0.0638177148299588 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 28 out of 93 Training Loss: 0.0722238361137284 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 29 out of 93 Training Loss: 0.08011237394533288 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 30 out of 93 Training Loss: 0.08959054809532296 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 31 out of 93 Training Loss: 0.09808434501758945 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 32 out of 93 Training Loss: 0.10516511558092367 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 33 out of 93 Training Loss: 0.11451516302771103 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 34 out of 93 Training Loss: 0.12409988327420485 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 35 out of 93 Training Loss: 0.13127020795366895 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 36 out of 93 Training Loss: 0.14102576256266963 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 37 out of 93 Training Loss: 0.1488298843847884 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 38 out of 93 Training Loss: 0.15626368254891765 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 39 out of 93 Training Loss: 0.16494637683502567 Test Loss: 0.008453670211813667\n",
      "Epoch: 14 Batch: 40 out of 93 Training Loss: 0.0018861684700357158 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 41 out of 93 Training Loss: 0.010906205487798377 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 42 out of 93 Training Loss: 0.019883204226742907 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 43 out of 93 Training Loss: 0.02980816734338872 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 44 out of 93 Training Loss: 0.039710971502016704 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 45 out of 93 Training Loss: 0.04885253680254094 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 46 out of 93 Training Loss: 0.05625626069809071 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 47 out of 93 Training Loss: 0.0648853024219977 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 48 out of 93 Training Loss: 0.07342245427275769 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 49 out of 93 Training Loss: 0.0838364762937533 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 50 out of 93 Training Loss: 0.09387703051174752 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 51 out of 93 Training Loss: 0.10246613898630015 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 52 out of 93 Training Loss: 0.11035901678110234 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 53 out of 93 Training Loss: 0.11797869435827009 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 54 out of 93 Training Loss: 0.1279174149719881 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 55 out of 93 Training Loss: 0.13643358878175488 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 56 out of 93 Training Loss: 0.14596211023012867 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 57 out of 93 Training Loss: 0.15528164568672648 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 58 out of 93 Training Loss: 0.16585062115768662 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 59 out of 93 Training Loss: 0.17446039381752482 Test Loss: 0.008452048440548506\n",
      "Epoch: 14 Batch: 60 out of 93 Training Loss: 0.0019876683598863683 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 61 out of 93 Training Loss: 0.011169202300022801 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 62 out of 93 Training Loss: 0.020213666046272477 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 63 out of 93 Training Loss: 0.030990255670856198 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 64 out of 93 Training Loss: 0.04049906381429311 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 65 out of 93 Training Loss: 0.05076527469814893 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 66 out of 93 Training Loss: 0.05836924831406351 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 67 out of 93 Training Loss: 0.06682431525574203 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 68 out of 93 Training Loss: 0.07627450968162294 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 69 out of 93 Training Loss: 0.08686761385784622 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 70 out of 93 Training Loss: 0.09413162446604248 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 71 out of 93 Training Loss: 0.10551248597935911 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 72 out of 93 Training Loss: 0.11485396712110515 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 73 out of 93 Training Loss: 0.1227572291626143 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 74 out of 93 Training Loss: 0.1317088521553683 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 75 out of 93 Training Loss: 0.1413436235396671 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 76 out of 93 Training Loss: 0.14999038646952387 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 77 out of 93 Training Loss: 0.1581629106311607 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 78 out of 93 Training Loss: 0.16764009478525396 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 79 out of 93 Training Loss: 0.17856990001187797 Test Loss: 0.008517625022002241\n",
      "Epoch: 14 Batch: 80 out of 93 Training Loss: 0.0020195610175355013 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 81 out of 93 Training Loss: 0.011784209991477303 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 82 out of 93 Training Loss: 0.020027257623754315 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 83 out of 93 Training Loss: 0.02957233146824675 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 84 out of 93 Training Loss: 0.03750276577719289 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 85 out of 93 Training Loss: 0.045896969857297715 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 86 out of 93 Training Loss: 0.05205981259294587 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 87 out of 93 Training Loss: 0.06232635782160598 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 88 out of 93 Training Loss: 0.07033566956468659 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 89 out of 93 Training Loss: 0.07934199937679606 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 90 out of 93 Training Loss: 0.09096675750859815 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 91 out of 93 Training Loss: 0.09816977161043125 Test Loss: 0.008625256151638248\n",
      "Epoch: 14 Batch: 92 out of 93 Training Loss: 0.10603150411569315 Test Loss: 0.008625256151638248\n",
      "Epoch: 15 Batch: 0 out of 93 Training Loss: 9.109557516151859e-05 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 1 out of 93 Training Loss: 0.009317249179847779 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 2 out of 93 Training Loss: 0.018702861973114552 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 3 out of 93 Training Loss: 0.02737885911858851 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 4 out of 93 Training Loss: 0.03574044176287228 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 5 out of 93 Training Loss: 0.04574032046742016 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 6 out of 93 Training Loss: 0.054110638917453824 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 7 out of 93 Training Loss: 0.06397347629911476 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 8 out of 93 Training Loss: 0.07358808548099571 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 9 out of 93 Training Loss: 0.0829518168503719 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 10 out of 93 Training Loss: 0.09028177813536697 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 11 out of 93 Training Loss: 0.09893937420941168 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 12 out of 93 Training Loss: 0.10820722126311833 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 13 out of 93 Training Loss: 0.11592690984628373 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 14 out of 93 Training Loss: 0.12824079359791452 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 15 out of 93 Training Loss: 0.13722487318239385 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 16 out of 93 Training Loss: 0.1473590439455884 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 17 out of 93 Training Loss: 0.1553425422208684 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 18 out of 93 Training Loss: 0.16369924752882892 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 19 out of 93 Training Loss: 0.17433387379071885 Test Loss: 0.008619183166460558\n",
      "Epoch: 15 Batch: 20 out of 93 Training Loss: 0.0019767910345130256 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 21 out of 93 Training Loss: 0.01160850581812194 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 22 out of 93 Training Loss: 0.019894921417408496 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 23 out of 93 Training Loss: 0.02904923093604377 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 24 out of 93 Training Loss: 0.037503290186696556 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 25 out of 93 Training Loss: 0.0464753463967376 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 26 out of 93 Training Loss: 0.055400289791696575 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 27 out of 93 Training Loss: 0.06430926938640406 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 28 out of 93 Training Loss: 0.07236695588665536 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 29 out of 93 Training Loss: 0.07993504843773773 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 30 out of 93 Training Loss: 0.09070758494647672 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 31 out of 93 Training Loss: 0.09949910706939628 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 32 out of 93 Training Loss: 0.10737724016519716 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 33 out of 93 Training Loss: 0.1148664496942096 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 34 out of 93 Training Loss: 0.12399125211971333 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 35 out of 93 Training Loss: 0.13435384371417097 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 36 out of 93 Training Loss: 0.14321388882684044 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 37 out of 93 Training Loss: 0.15049206345441274 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 38 out of 93 Training Loss: 0.16037506210716895 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 39 out of 93 Training Loss: 0.16977360910835199 Test Loss: 0.008481158874928951\n",
      "Epoch: 15 Batch: 40 out of 93 Training Loss: 0.0019101345161663516 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 41 out of 93 Training Loss: 0.01034549839745631 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 42 out of 93 Training Loss: 0.018328299112127924 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 43 out of 93 Training Loss: 0.02505770076017251 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 44 out of 93 Training Loss: 0.031506832055257464 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 45 out of 93 Training Loss: 0.04071891710113158 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 46 out of 93 Training Loss: 0.04942763533394208 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 47 out of 93 Training Loss: 0.05868731748263707 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 48 out of 93 Training Loss: 0.06731068558941951 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 49 out of 93 Training Loss: 0.07590949658255448 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 50 out of 93 Training Loss: 0.08430856123517623 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 51 out of 93 Training Loss: 0.09457085870157352 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 52 out of 93 Training Loss: 0.1030189304793941 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 53 out of 93 Training Loss: 0.11262716103296151 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 54 out of 93 Training Loss: 0.12359513185869327 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 55 out of 93 Training Loss: 0.1328529485682713 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 56 out of 93 Training Loss: 0.14231796964954008 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 57 out of 93 Training Loss: 0.15120395395855774 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 58 out of 93 Training Loss: 0.1608267625043856 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 59 out of 93 Training Loss: 0.16867227323304285 Test Loss: 0.008533103730190884\n",
      "Epoch: 15 Batch: 60 out of 93 Training Loss: 0.001893315547571245 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 61 out of 93 Training Loss: 0.01208862111853129 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 62 out of 93 Training Loss: 0.02256166105108029 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 63 out of 93 Training Loss: 0.03147052329914338 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 64 out of 93 Training Loss: 0.03980637350069052 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 65 out of 93 Training Loss: 0.04942791079120404 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 66 out of 93 Training Loss: 0.05919902686910397 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 67 out of 93 Training Loss: 0.06915757627175814 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 68 out of 93 Training Loss: 0.07714961291240222 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 69 out of 93 Training Loss: 0.08501868982748753 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 70 out of 93 Training Loss: 0.09392441817508704 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 71 out of 93 Training Loss: 0.10296236452595955 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 72 out of 93 Training Loss: 0.11263915252821213 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 73 out of 93 Training Loss: 0.12035083918781644 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 74 out of 93 Training Loss: 0.1299849921739257 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 75 out of 93 Training Loss: 0.13891358635337717 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 76 out of 93 Training Loss: 0.14808803292872078 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 77 out of 93 Training Loss: 0.15798664520444042 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 78 out of 93 Training Loss: 0.16582523248107797 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 79 out of 93 Training Loss: 0.17354021602259642 Test Loss: 0.008455050389536402\n",
      "Epoch: 15 Batch: 80 out of 93 Training Loss: 0.0019446467959658184 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 81 out of 93 Training Loss: 0.010087830571211962 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 82 out of 93 Training Loss: 0.016893365511424927 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 83 out of 93 Training Loss: 0.02549720471514025 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 84 out of 93 Training Loss: 0.035368294546134854 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 85 out of 93 Training Loss: 0.04316586544526377 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 86 out of 93 Training Loss: 0.05100334072274723 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 87 out of 93 Training Loss: 0.05956445364070692 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 88 out of 93 Training Loss: 0.06731703234625616 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 89 out of 93 Training Loss: 0.07608402343256035 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 90 out of 93 Training Loss: 0.0853860053212718 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 91 out of 93 Training Loss: 0.09467137986583271 Test Loss: 0.008326194164427843\n",
      "Epoch: 15 Batch: 92 out of 93 Training Loss: 0.10180826540825524 Test Loss: 0.008326194164427843\n",
      "Epoch: 16 Batch: 0 out of 93 Training Loss: 0.00010869825278879494 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 1 out of 93 Training Loss: 0.007705052718720449 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 2 out of 93 Training Loss: 0.01691824417581321 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 3 out of 93 Training Loss: 0.025827215388617528 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 4 out of 93 Training Loss: 0.03580402430166961 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 5 out of 93 Training Loss: 0.04461237356086732 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 6 out of 93 Training Loss: 0.05184293292482854 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 7 out of 93 Training Loss: 0.060131406747005 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 8 out of 93 Training Loss: 0.07024658784290315 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 9 out of 93 Training Loss: 0.07961508572121621 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 10 out of 93 Training Loss: 0.09031842310001613 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 11 out of 93 Training Loss: 0.09913896150907041 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 12 out of 93 Training Loss: 0.10645567240213515 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 13 out of 93 Training Loss: 0.11489578137194277 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 14 out of 93 Training Loss: 0.12216943303143145 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 15 out of 93 Training Loss: 0.13030955089276197 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 16 out of 93 Training Loss: 0.13864348070716026 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 17 out of 93 Training Loss: 0.14684574292992714 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 18 out of 93 Training Loss: 0.1556217454934633 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 19 out of 93 Training Loss: 0.16514119492863777 Test Loss: 0.008235284973951902\n",
      "Epoch: 16 Batch: 20 out of 93 Training Loss: 0.0018772291686527578 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 21 out of 93 Training Loss: 0.01082897323334144 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 22 out of 93 Training Loss: 0.018586221590279804 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 23 out of 93 Training Loss: 0.026118537384658323 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 24 out of 93 Training Loss: 0.0349013050753765 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 25 out of 93 Training Loss: 0.04355253276565598 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 26 out of 93 Training Loss: 0.05203237754443215 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 27 out of 93 Training Loss: 0.06297671699115562 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 28 out of 93 Training Loss: 0.0720386039201312 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 29 out of 93 Training Loss: 0.07897604440489339 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 30 out of 93 Training Loss: 0.08858070426770973 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 31 out of 93 Training Loss: 0.0978598575774722 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 32 out of 93 Training Loss: 0.10621455961057472 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 33 out of 93 Training Loss: 0.11510025707223939 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 34 out of 93 Training Loss: 0.12430099674650955 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 35 out of 93 Training Loss: 0.13363643174210119 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 36 out of 93 Training Loss: 0.14094783037120032 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 37 out of 93 Training Loss: 0.14909848335349488 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 38 out of 93 Training Loss: 0.15805713224375176 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 39 out of 93 Training Loss: 0.16696369133108782 Test Loss: 0.008193182885985483\n",
      "Epoch: 16 Batch: 40 out of 93 Training Loss: 0.0018839843077646712 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 41 out of 93 Training Loss: 0.009254456262110375 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 42 out of 93 Training Loss: 0.019833692113875055 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 43 out of 93 Training Loss: 0.02775712287706008 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 44 out of 93 Training Loss: 0.03631256217789521 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 45 out of 93 Training Loss: 0.04453576798272004 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 46 out of 93 Training Loss: 0.054487806509255075 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 47 out of 93 Training Loss: 0.0639750526724445 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 48 out of 93 Training Loss: 0.0719505341230022 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 49 out of 93 Training Loss: 0.08005200954806677 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 50 out of 93 Training Loss: 0.08797628781479469 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 51 out of 93 Training Loss: 0.0961530355243074 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 52 out of 93 Training Loss: 0.10594316268992296 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 53 out of 93 Training Loss: 0.11480017541628948 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 54 out of 93 Training Loss: 0.1247980787856566 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 55 out of 93 Training Loss: 0.13249813136365882 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 56 out of 93 Training Loss: 0.14104905002471677 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 57 out of 93 Training Loss: 0.15096433111187688 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 58 out of 93 Training Loss: 0.1598413942819523 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 59 out of 93 Training Loss: 0.16819572006073466 Test Loss: 0.008123799184845253\n",
      "Epoch: 16 Batch: 60 out of 93 Training Loss: 0.0018879645528793198 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 61 out of 93 Training Loss: 0.01033025188618897 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 62 out of 93 Training Loss: 0.019435294440627082 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 63 out of 93 Training Loss: 0.02822468942278622 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 64 out of 93 Training Loss: 0.03643835569047926 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 65 out of 93 Training Loss: 0.04401185643175243 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 66 out of 93 Training Loss: 0.05065544648343323 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 67 out of 93 Training Loss: 0.058189160658657535 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 68 out of 93 Training Loss: 0.06606752099716662 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 69 out of 93 Training Loss: 0.07575852843248843 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 70 out of 93 Training Loss: 0.08380440389984845 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 71 out of 93 Training Loss: 0.09222432272756098 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 72 out of 93 Training Loss: 0.10061187995845078 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 73 out of 93 Training Loss: 0.10836219787845014 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 74 out of 93 Training Loss: 0.11705338303247093 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 75 out of 93 Training Loss: 0.127356324347347 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 76 out of 93 Training Loss: 0.13702494185665248 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 77 out of 93 Training Loss: 0.14528957102695106 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 78 out of 93 Training Loss: 0.15361148398616908 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 79 out of 93 Training Loss: 0.16161842271932958 Test Loss: 0.008347067473964258\n",
      "Epoch: 16 Batch: 80 out of 93 Training Loss: 0.0018162681891658611 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 81 out of 93 Training Loss: 0.010438680758986742 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 82 out of 93 Training Loss: 0.018287922365877896 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 83 out of 93 Training Loss: 0.02707487542024639 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 84 out of 93 Training Loss: 0.03621209237566975 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 85 out of 93 Training Loss: 0.04438337415299204 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 86 out of 93 Training Loss: 0.05121317796251562 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 87 out of 93 Training Loss: 0.06139386456302193 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 88 out of 93 Training Loss: 0.06921244330546644 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 89 out of 93 Training Loss: 0.0791046527384856 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 90 out of 93 Training Loss: 0.08675515476456669 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 91 out of 93 Training Loss: 0.09657952852389601 Test Loss: 0.008211287077177654\n",
      "Epoch: 16 Batch: 92 out of 93 Training Loss: 0.10389317676267412 Test Loss: 0.008211287077177654\n",
      "Epoch: 17 Batch: 0 out of 93 Training Loss: 8.79462928541245e-05 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 1 out of 93 Training Loss: 0.00891078227469998 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 2 out of 93 Training Loss: 0.0184012750283845 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 3 out of 93 Training Loss: 0.028574138519264037 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 4 out of 93 Training Loss: 0.037367293250656894 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 5 out of 93 Training Loss: 0.046187860530710986 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 6 out of 93 Training Loss: 0.054800276284015945 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 7 out of 93 Training Loss: 0.06239658511514144 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 8 out of 93 Training Loss: 0.07183576199496465 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 9 out of 93 Training Loss: 0.08017582363719421 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 10 out of 93 Training Loss: 0.08891805830681997 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 11 out of 93 Training Loss: 0.09731528080338912 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 12 out of 93 Training Loss: 0.10622414212012964 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 13 out of 93 Training Loss: 0.11316120774755555 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 14 out of 93 Training Loss: 0.12196428199569063 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 15 out of 93 Training Loss: 0.13047714122841436 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 16 out of 93 Training Loss: 0.13870418501356918 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 17 out of 93 Training Loss: 0.14787389395097572 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 18 out of 93 Training Loss: 0.15616650657067377 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 19 out of 93 Training Loss: 0.16298678248459775 Test Loss: 0.008184731726280668\n",
      "Epoch: 17 Batch: 20 out of 93 Training Loss: 0.0018377286263141024 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 21 out of 93 Training Loss: 0.010394406586173473 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 22 out of 93 Training Loss: 0.018745908594909606 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 23 out of 93 Training Loss: 0.027222232043031154 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 24 out of 93 Training Loss: 0.03671363190490335 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 25 out of 93 Training Loss: 0.046311316161635814 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 26 out of 93 Training Loss: 0.05361100992861718 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 27 out of 93 Training Loss: 0.0626632902652356 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 28 out of 93 Training Loss: 0.068979210767183 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 29 out of 93 Training Loss: 0.07688808309588163 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 30 out of 93 Training Loss: 0.0866356069103214 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 31 out of 93 Training Loss: 0.0937871067665848 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 32 out of 93 Training Loss: 0.10296971545297234 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 33 out of 93 Training Loss: 0.11235182554203599 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 34 out of 93 Training Loss: 0.12049342606890528 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 35 out of 93 Training Loss: 0.12959216077554553 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 36 out of 93 Training Loss: 0.13893556416708558 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 37 out of 93 Training Loss: 0.1462966171905729 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 38 out of 93 Training Loss: 0.15468509736213415 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 39 out of 93 Training Loss: 0.16395392602983444 Test Loss: 0.008232181299139153\n",
      "Epoch: 17 Batch: 40 out of 93 Training Loss: 0.0018678819619202837 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 41 out of 93 Training Loss: 0.01127515079901459 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 42 out of 93 Training Loss: 0.01956373451725485 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 43 out of 93 Training Loss: 0.028395018526175042 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 44 out of 93 Training Loss: 0.03711692801193239 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 45 out of 93 Training Loss: 0.04529753046558144 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 46 out of 93 Training Loss: 0.05288073465675952 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 47 out of 93 Training Loss: 0.05996698186249377 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 48 out of 93 Training Loss: 0.06775729636178257 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 49 out of 93 Training Loss: 0.07506477738247158 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 50 out of 93 Training Loss: 0.0825357278667474 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 51 out of 93 Training Loss: 0.09002306823135259 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 52 out of 93 Training Loss: 0.09930560503602864 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 53 out of 93 Training Loss: 0.10927352820039632 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 54 out of 93 Training Loss: 0.11675166849494817 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 55 out of 93 Training Loss: 0.12535595752746703 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 56 out of 93 Training Loss: 0.13345586460531594 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 57 out of 93 Training Loss: 0.14246852275431993 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 58 out of 93 Training Loss: 0.15256283291132094 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 59 out of 93 Training Loss: 0.16239627588988187 Test Loss: 0.008495142344724049\n",
      "Epoch: 17 Batch: 60 out of 93 Training Loss: 0.001850796898334347 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 61 out of 93 Training Loss: 0.010485171375303588 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 62 out of 93 Training Loss: 0.02057851388814958 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 63 out of 93 Training Loss: 0.029305098613231502 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 64 out of 93 Training Loss: 0.03710919761794718 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 65 out of 93 Training Loss: 0.04663635281610402 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 66 out of 93 Training Loss: 0.05462909819322737 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 67 out of 93 Training Loss: 0.06265554534035833 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 68 out of 93 Training Loss: 0.07048923386025341 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 69 out of 93 Training Loss: 0.07892297351497324 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 70 out of 93 Training Loss: 0.08786664301294 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 71 out of 93 Training Loss: 0.0972291413112274 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 72 out of 93 Training Loss: 0.10453538879516633 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 73 out of 93 Training Loss: 0.11273957978698523 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 74 out of 93 Training Loss: 0.12274975891920836 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 75 out of 93 Training Loss: 0.13320692725244077 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 76 out of 93 Training Loss: 0.14196809198471816 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 77 out of 93 Training Loss: 0.1500819689011863 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 78 out of 93 Training Loss: 0.15802173506233008 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 79 out of 93 Training Loss: 0.1653414401574722 Test Loss: 0.007979200052266771\n",
      "Epoch: 17 Batch: 80 out of 93 Training Loss: 0.001872781108719037 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 81 out of 93 Training Loss: 0.010161922689181493 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 82 out of 93 Training Loss: 0.018654493990939783 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 83 out of 93 Training Loss: 0.026928686912757085 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 84 out of 93 Training Loss: 0.033616914324116634 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 85 out of 93 Training Loss: 0.04166453695262663 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 86 out of 93 Training Loss: 0.049125982358705925 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 87 out of 93 Training Loss: 0.05568024693394892 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 88 out of 93 Training Loss: 0.06663880953903191 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 89 out of 93 Training Loss: 0.0747807844575762 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 90 out of 93 Training Loss: 0.08352175439114563 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 91 out of 93 Training Loss: 0.0915371327694773 Test Loss: 0.008354984943500975\n",
      "Epoch: 17 Batch: 92 out of 93 Training Loss: 0.09856933160091631 Test Loss: 0.008354984943500975\n",
      "Epoch: 18 Batch: 0 out of 93 Training Loss: 8.667419634519084e-05 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 1 out of 93 Training Loss: 0.008452383530957083 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 2 out of 93 Training Loss: 0.017201246423346382 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 3 out of 93 Training Loss: 0.024039410249961 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 4 out of 93 Training Loss: 0.03326888867623864 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 5 out of 93 Training Loss: 0.041315715955269915 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 6 out of 93 Training Loss: 0.0492871293888217 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 7 out of 93 Training Loss: 0.05810094178624211 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 8 out of 93 Training Loss: 0.0655294519007927 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 9 out of 93 Training Loss: 0.07457426582433044 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 10 out of 93 Training Loss: 0.082572206118775 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 11 out of 93 Training Loss: 0.0907051332385069 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 12 out of 93 Training Loss: 0.09922930338389932 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 13 out of 93 Training Loss: 0.10765600969053565 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 14 out of 93 Training Loss: 0.11599054393328487 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 15 out of 93 Training Loss: 0.12483240217871724 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 16 out of 93 Training Loss: 0.1330875337213999 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 17 out of 93 Training Loss: 0.14333909396983444 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 18 out of 93 Training Loss: 0.15079794843651115 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 19 out of 93 Training Loss: 0.15861731973446666 Test Loss: 0.00836632489650087\n",
      "Epoch: 18 Batch: 20 out of 93 Training Loss: 0.0017936256564921012 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 21 out of 93 Training Loss: 0.010497568998462544 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 22 out of 93 Training Loss: 0.019275483567244397 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 23 out of 93 Training Loss: 0.028337729055411206 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 24 out of 93 Training Loss: 0.036504182856506695 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 25 out of 93 Training Loss: 0.04592807952684819 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 26 out of 93 Training Loss: 0.054731738645560135 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 27 out of 93 Training Loss: 0.06199361838770567 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 28 out of 93 Training Loss: 0.06930587662754117 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 29 out of 93 Training Loss: 0.07836342359331905 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 30 out of 93 Training Loss: 0.08615333110464274 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 31 out of 93 Training Loss: 0.09395281494033991 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 32 out of 93 Training Loss: 0.1039268131218618 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 33 out of 93 Training Loss: 0.11246008508277594 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 34 out of 93 Training Loss: 0.12002413476256191 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 35 out of 93 Training Loss: 0.12942834979293405 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 36 out of 93 Training Loss: 0.13810167776790916 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 37 out of 93 Training Loss: 0.1466672833859688 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 38 out of 93 Training Loss: 0.15493269021061717 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 39 out of 93 Training Loss: 0.16509582976249515 Test Loss: 0.00829566994004629\n",
      "Epoch: 18 Batch: 40 out of 93 Training Loss: 0.0018784200150156597 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 41 out of 93 Training Loss: 0.008496797301956472 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 42 out of 93 Training Loss: 0.016946445808895885 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 43 out of 93 Training Loss: 0.024440863293745577 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 44 out of 93 Training Loss: 0.03150919325012809 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 45 out of 93 Training Loss: 0.04154140281785375 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 46 out of 93 Training Loss: 0.0495710863109315 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 47 out of 93 Training Loss: 0.05685088050846106 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 48 out of 93 Training Loss: 0.0650195480633164 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 49 out of 93 Training Loss: 0.07321019948754555 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 50 out of 93 Training Loss: 0.08123907179866081 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 51 out of 93 Training Loss: 0.08967142192009932 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 52 out of 93 Training Loss: 0.09796280705664402 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 53 out of 93 Training Loss: 0.10732475028667694 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 54 out of 93 Training Loss: 0.11505770043764359 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 55 out of 93 Training Loss: 0.12391210359815603 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 56 out of 93 Training Loss: 0.13226566382978205 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 57 out of 93 Training Loss: 0.14170515270266776 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 58 out of 93 Training Loss: 0.15083746345076804 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 59 out of 93 Training Loss: 0.15990592831108813 Test Loss: 0.008040787779133429\n",
      "Epoch: 18 Batch: 60 out of 93 Training Loss: 0.0018096281308997322 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 61 out of 93 Training Loss: 0.010603138627516096 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 62 out of 93 Training Loss: 0.020443082237647837 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 63 out of 93 Training Loss: 0.029670436317132776 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 64 out of 93 Training Loss: 0.03923624140213615 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 65 out of 93 Training Loss: 0.048681491436468424 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 66 out of 93 Training Loss: 0.05896185656081325 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 67 out of 93 Training Loss: 0.06687750891785509 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 68 out of 93 Training Loss: 0.0743866119627226 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 69 out of 93 Training Loss: 0.08473090865652448 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 70 out of 93 Training Loss: 0.09190173671584016 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 71 out of 93 Training Loss: 0.09941675924699193 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 72 out of 93 Training Loss: 0.10785873365591651 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 73 out of 93 Training Loss: 0.11635541302155143 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 74 out of 93 Training Loss: 0.12326811804439312 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 75 out of 93 Training Loss: 0.13157249513085373 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 76 out of 93 Training Loss: 0.14056782788600214 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 77 out of 93 Training Loss: 0.1482953656558264 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 78 out of 93 Training Loss: 0.15636443012397178 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 79 out of 93 Training Loss: 0.1634404500108529 Test Loss: 0.008197259454225952\n",
      "Epoch: 18 Batch: 80 out of 93 Training Loss: 0.0018519456539386582 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 81 out of 93 Training Loss: 0.01062863739618004 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 82 out of 93 Training Loss: 0.019771007359408743 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 83 out of 93 Training Loss: 0.02909357427098692 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 84 out of 93 Training Loss: 0.0372891225893134 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 85 out of 93 Training Loss: 0.04703907994964064 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 86 out of 93 Training Loss: 0.05574197834768237 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 87 out of 93 Training Loss: 0.06579011818804682 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 88 out of 93 Training Loss: 0.07275250554495395 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 89 out of 93 Training Loss: 0.08071602601968587 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 90 out of 93 Training Loss: 0.09130874276571811 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 91 out of 93 Training Loss: 0.10014685523175539 Test Loss: 0.00803016989745877\n",
      "Epoch: 18 Batch: 92 out of 93 Training Loss: 0.10774190072380842 Test Loss: 0.00803016989745877\n",
      "Epoch: 19 Batch: 0 out of 93 Training Loss: 9.643405635831177e-05 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 1 out of 93 Training Loss: 0.00960606735159633 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 2 out of 93 Training Loss: 0.01834747873206613 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 3 out of 93 Training Loss: 0.02592693528120396 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 4 out of 93 Training Loss: 0.03531088193838475 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 5 out of 93 Training Loss: 0.04287177257199762 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 6 out of 93 Training Loss: 0.05182164654095647 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 7 out of 93 Training Loss: 0.06035009611357925 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 8 out of 93 Training Loss: 0.06982919879217622 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 9 out of 93 Training Loss: 0.07900268796791313 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 10 out of 93 Training Loss: 0.08738087329973457 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 11 out of 93 Training Loss: 0.09488705804531453 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 12 out of 93 Training Loss: 0.10297114008997557 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 13 out of 93 Training Loss: 0.11155186666135666 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 14 out of 93 Training Loss: 0.11914422109683034 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 15 out of 93 Training Loss: 0.12787317603786466 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 16 out of 93 Training Loss: 0.13582849807997224 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 17 out of 93 Training Loss: 0.14317514819984314 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 18 out of 93 Training Loss: 0.1516755975592601 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 19 out of 93 Training Loss: 0.16046314759139893 Test Loss: 0.008480053691362793\n",
      "Epoch: 19 Batch: 20 out of 93 Training Loss: 0.0018208935854773236 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 21 out of 93 Training Loss: 0.009507258981261701 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 22 out of 93 Training Loss: 0.017502028122339697 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 23 out of 93 Training Loss: 0.026020729541573973 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 24 out of 93 Training Loss: 0.03440407160649106 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 25 out of 93 Training Loss: 0.044060315564070196 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 26 out of 93 Training Loss: 0.05018890984335944 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 27 out of 93 Training Loss: 0.0584810670463185 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 28 out of 93 Training Loss: 0.0670922413466315 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 29 out of 93 Training Loss: 0.07614546325037286 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 30 out of 93 Training Loss: 0.0869264841077666 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 31 out of 93 Training Loss: 0.09515333976576135 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 32 out of 93 Training Loss: 0.10220158714780614 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 33 out of 93 Training Loss: 0.10995405269766256 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 34 out of 93 Training Loss: 0.11860809577608511 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 35 out of 93 Training Loss: 0.126775752845947 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 36 out of 93 Training Loss: 0.1350070751270096 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 37 out of 93 Training Loss: 0.14384978460127518 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 38 out of 93 Training Loss: 0.1507560239171426 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 39 out of 93 Training Loss: 0.15973516842329905 Test Loss: 0.008217995055019855\n",
      "Epoch: 19 Batch: 40 out of 93 Training Loss: 0.0018204383722294193 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 41 out of 93 Training Loss: 0.009767951274548851 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 42 out of 93 Training Loss: 0.01854303182873615 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 43 out of 93 Training Loss: 0.026468290778135145 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 44 out of 93 Training Loss: 0.0347509605980266 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 45 out of 93 Training Loss: 0.04343837948355564 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 46 out of 93 Training Loss: 0.051273706199859465 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 47 out of 93 Training Loss: 0.05846703920352944 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 48 out of 93 Training Loss: 0.06617786252710708 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 49 out of 93 Training Loss: 0.07601582428280004 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 50 out of 93 Training Loss: 0.08545929828498253 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 51 out of 93 Training Loss: 0.09362478630456814 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 52 out of 93 Training Loss: 0.10100225062880405 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 53 out of 93 Training Loss: 0.10899682512346395 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 54 out of 93 Training Loss: 0.11876148247930893 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 55 out of 93 Training Loss: 0.12703506631616243 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 56 out of 93 Training Loss: 0.13518342731360086 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 57 out of 93 Training Loss: 0.14263540116909632 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 58 out of 93 Training Loss: 0.15000211989346632 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 59 out of 93 Training Loss: 0.15811241308066734 Test Loss: 0.00836656517772512\n",
      "Epoch: 19 Batch: 60 out of 93 Training Loss: 0.001790698105151667 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 61 out of 93 Training Loss: 0.011806438164467825 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 62 out of 93 Training Loss: 0.02048266907190801 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 63 out of 93 Training Loss: 0.0294570386872244 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 64 out of 93 Training Loss: 0.03848876659726621 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 65 out of 93 Training Loss: 0.04788493872588397 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 66 out of 93 Training Loss: 0.05454073096593739 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 67 out of 93 Training Loss: 0.06391312084128978 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 68 out of 93 Training Loss: 0.07324353787084939 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 69 out of 93 Training Loss: 0.08119154344281079 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 70 out of 93 Training Loss: 0.08998662694325568 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 71 out of 93 Training Loss: 0.09827751382222297 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 72 out of 93 Training Loss: 0.1072106621690643 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 73 out of 93 Training Loss: 0.11445491011222722 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 74 out of 93 Training Loss: 0.12322013168563964 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 75 out of 93 Training Loss: 0.13162717032214524 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 76 out of 93 Training Loss: 0.1410071262620938 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 77 out of 93 Training Loss: 0.14780129906689646 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 78 out of 93 Training Loss: 0.15627008066480877 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 79 out of 93 Training Loss: 0.16460494738971712 Test Loss: 0.008287176447497173\n",
      "Epoch: 19 Batch: 80 out of 93 Training Loss: 0.0018485162141748785 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 81 out of 93 Training Loss: 0.011331691566390646 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 82 out of 93 Training Loss: 0.019922986786348476 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 83 out of 93 Training Loss: 0.02748465553997244 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 84 out of 93 Training Loss: 0.036130643609447136 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 85 out of 93 Training Loss: 0.04452835039375509 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 86 out of 93 Training Loss: 0.05332211793540205 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 87 out of 93 Training Loss: 0.06342963424651112 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 88 out of 93 Training Loss: 0.07104569829208936 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 89 out of 93 Training Loss: 0.07931094772322263 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 90 out of 93 Training Loss: 0.08798599678231563 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 91 out of 93 Training Loss: 0.09654798514349545 Test Loss: 0.008010896134444258\n",
      "Epoch: 19 Batch: 92 out of 93 Training Loss: 0.1058066856781968 Test Loss: 0.008010896134444258\n",
      "Epoch: 20 Batch: 0 out of 93 Training Loss: 9.544591309242351e-05 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 1 out of 93 Training Loss: 0.007693413895384599 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 2 out of 93 Training Loss: 0.017660085362211992 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 3 out of 93 Training Loss: 0.026624151755885412 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 4 out of 93 Training Loss: 0.03503328307421617 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 5 out of 93 Training Loss: 0.04193396099732928 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 6 out of 93 Training Loss: 0.04992494151817374 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 7 out of 93 Training Loss: 0.05956810691283755 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 8 out of 93 Training Loss: 0.06716700435505919 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 9 out of 93 Training Loss: 0.0773994473450046 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 10 out of 93 Training Loss: 0.085412700445221 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 11 out of 93 Training Loss: 0.09355792940484099 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 12 out of 93 Training Loss: 0.10244340334908776 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 13 out of 93 Training Loss: 0.11089713663683944 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 14 out of 93 Training Loss: 0.11923493982182555 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 15 out of 93 Training Loss: 0.12750096876995376 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 16 out of 93 Training Loss: 0.13696485363768152 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 17 out of 93 Training Loss: 0.14589042474405578 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 18 out of 93 Training Loss: 0.15442903690861276 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 19 out of 93 Training Loss: 0.16167885648907832 Test Loss: 0.008153001312166452\n",
      "Epoch: 20 Batch: 20 out of 93 Training Loss: 0.0018372235305849382 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 21 out of 93 Training Loss: 0.00960440677108801 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 22 out of 93 Training Loss: 0.01751636736544407 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 23 out of 93 Training Loss: 0.026442834404135113 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 24 out of 93 Training Loss: 0.035006730113947754 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 25 out of 93 Training Loss: 0.04324535489531792 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 26 out of 93 Training Loss: 0.051727925655269985 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 27 out of 93 Training Loss: 0.0606715346172694 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 28 out of 93 Training Loss: 0.06846904917138255 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 29 out of 93 Training Loss: 0.07611506594794429 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 30 out of 93 Training Loss: 0.08404861087428964 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 31 out of 93 Training Loss: 0.09254094375746882 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 32 out of 93 Training Loss: 0.10068303788530267 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 33 out of 93 Training Loss: 0.10874989791291392 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 34 out of 93 Training Loss: 0.11698626144307292 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 35 out of 93 Training Loss: 0.1255034103475753 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 36 out of 93 Training Loss: 0.1346072766416017 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 37 out of 93 Training Loss: 0.1433512919999901 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 38 out of 93 Training Loss: 0.150905629847968 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 39 out of 93 Training Loss: 0.15954367652984894 Test Loss: 0.008079339877109636\n",
      "Epoch: 20 Batch: 40 out of 93 Training Loss: 0.001803458350288231 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 41 out of 93 Training Loss: 0.009843416194009144 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 42 out of 93 Training Loss: 0.017346633745866376 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 43 out of 93 Training Loss: 0.026074256895618993 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 44 out of 93 Training Loss: 0.0345894276709729 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 45 out of 93 Training Loss: 0.04220419531552728 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 46 out of 93 Training Loss: 0.049028740412133294 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 47 out of 93 Training Loss: 0.05824077889187868 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 48 out of 93 Training Loss: 0.06775218542529876 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 49 out of 93 Training Loss: 0.07576981760426099 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 50 out of 93 Training Loss: 0.08487933702631528 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 51 out of 93 Training Loss: 0.09343921873583133 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 52 out of 93 Training Loss: 0.10242654491080577 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 53 out of 93 Training Loss: 0.11144231833382184 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 54 out of 93 Training Loss: 0.11921729348464544 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 55 out of 93 Training Loss: 0.12702248493074114 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 56 out of 93 Training Loss: 0.1351544015654796 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 57 out of 93 Training Loss: 0.14447830026833947 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 58 out of 93 Training Loss: 0.1525179563635462 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 59 out of 93 Training Loss: 0.16005356903983886 Test Loss: 0.008137149397622456\n",
      "Epoch: 20 Batch: 60 out of 93 Training Loss: 0.0018035039141308168 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 61 out of 93 Training Loss: 0.010766808485938202 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 62 out of 93 Training Loss: 0.0187413437127601 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 63 out of 93 Training Loss: 0.02742221446926702 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 64 out of 93 Training Loss: 0.036348043551994454 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 65 out of 93 Training Loss: 0.045478260686947 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 66 out of 93 Training Loss: 0.05198384084026326 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 67 out of 93 Training Loss: 0.05932094350676049 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 68 out of 93 Training Loss: 0.06806656073997724 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 69 out of 93 Training Loss: 0.07649791993419636 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 70 out of 93 Training Loss: 0.08478360723922956 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 71 out of 93 Training Loss: 0.09215487128342498 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 72 out of 93 Training Loss: 0.09982970876838076 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 73 out of 93 Training Loss: 0.10661182001451958 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 74 out of 93 Training Loss: 0.11525856990586031 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 75 out of 93 Training Loss: 0.1228461289613973 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 76 out of 93 Training Loss: 0.13190403728033412 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 77 out of 93 Training Loss: 0.1407276248394977 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 78 out of 93 Training Loss: 0.15065934470142234 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 79 out of 93 Training Loss: 0.15927864944781173 Test Loss: 0.008254343347454613\n",
      "Epoch: 20 Batch: 80 out of 93 Training Loss: 0.001812725503982535 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 81 out of 93 Training Loss: 0.012418343861640922 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 82 out of 93 Training Loss: 0.018792073884101146 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 83 out of 93 Training Loss: 0.027214572475345367 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 84 out of 93 Training Loss: 0.03745897178450369 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 85 out of 93 Training Loss: 0.04660228052088761 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 86 out of 93 Training Loss: 0.055298211694748634 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 87 out of 93 Training Loss: 0.06274119502777004 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 88 out of 93 Training Loss: 0.07168096694076204 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 89 out of 93 Training Loss: 0.08086589462036037 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 90 out of 93 Training Loss: 0.0875654995339527 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 91 out of 93 Training Loss: 0.09489237069064521 Test Loss: 0.00809306896884333\n",
      "Epoch: 20 Batch: 92 out of 93 Training Loss: 0.10328486486250305 Test Loss: 0.00809306896884333\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import SmoothL1Loss\n",
    "\n",
    "trainlosses, testlosses = model.fit(trainloader = trainloader,\n",
    "                                    validationloader = valloader,\n",
    "                                    loss = SmoothL1Loss,\n",
    "                                    optim = Adam,\n",
    "                                    lr=0.001,\n",
    "                                    epochs = 20, \n",
    "                                    val_per_batch = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainlosses, label = 'Training Losses')\n",
    "plt.plot(testlosses, label = 'Testing Losses')\n",
    "plt.ylabel('Losses')\n",
    "plt.xlabel('Batch * Epoch')\n",
    "plt.legend()\n",
    "plt.title('Losses Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, expected = model.test(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_from = 0\n",
    "val_to = 20\n",
    "\n",
    "plt.plot(result[val_from:val_to], label = 'Result')\n",
    "plt.plot(expected[val_from:val_to], label = 'Expected')\n",
    "plt.ylabel('Wind Speed (Normalized)')\n",
    "plt.xticks(range(val_from, val_to))\n",
    "plt.xlabel('Time Range')\n",
    "plt.legend()\n",
    "plt.title('Model Output Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm-v1  - dir Created\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lstm-v1/model_cuda.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-cc91a4f2364c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm-v1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_optim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Wind-Speed-Prediction/model.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, save_optim)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mNAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_cuda.pt'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'model_cpu.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model saved in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msave_optim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lstm-v1/model_cuda.pt'"
     ]
    }
   ],
   "source": [
    "model.save('lstm-v1', save_optim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
