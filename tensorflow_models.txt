1. CNN Model:
i. CNN-1:

model = Sequential(name="cnn-2")

model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=trainX.shape[-2:], name="conv-1"))
model.add(MaxPooling1D(pool_size=2, name="pool-1"))
model.add(Dropout(0.2, name="drop-1"))

model.add(Flatten(name="flatten-1"))
model.add(RepeatVector(future_outputs, name="RepeatVector-1"))

model.add(TimeDistributed(Dense(1, name="dense-1")))

model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')
...............................................................................................................
(loss: 0.4532 - val_loss: 0.5142) (CNN-1 is good) 
...............................................................................................................
ii. CNN-2:

model = Sequential(name="cnn-2")

model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=trainX.shape[-2:], name="conv-1"))
model.add(MaxPooling1D(pool_size=2, name="pool-1"))
model.add(Dropout(0.2, name="drop-1"))

model.add(Flatten(name="flatten-1"))
model.add(RepeatVector(future_outputs, name="RepeatVector-1"))

model.add(TimeDistributed(Dense(1, name="dense-1")))

model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')
.....................................................................................................................
(loss: 0.4942 - val_loss: 0.5479) (CNN-2 is worse than CNN-1) (CNN-1 is best now)
.....................................................................................................................
iii. CNN-3:
model = Sequential(name="cnn-3")

model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=trainX.shape[-2:], name="conv-1"))
model.add(MaxPooling1D(pool_size=2, name="pool-1"))
model.add(Dropout(0.2, name="drop-1"))

model.add(Flatten(name="flatten-1"))
model.add(RepeatVector(future_outputs, name="RepeatVector-1"))

model.add(TimeDistributed(Dense(1, name="dense-1")))

model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')
....................................................................................................................
(loss: 0.4521 - val_loss: 0.5123) (CNN-3 is little worse than CNN-1 in overall) (CNN-1 is best now)
[Best Config]([conv-1: kernel_size=3])
....................................................................................................................

ii. CNN-2: 

model = Sequential(name="cnn-2")

model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=trainX.shape[-2:], name="conv-1"))
model.add(Conv1D(filters=64, kernel_size=3, activation='relu', name="conv-2"))
model.add(MaxPooling1D(pool_size=2, name="pool-1"))
model.add(Dropout(0.2, name="drop-1"))

model.add(Flatten(name="flatten-1"))
model.add(RepeatVector(future_outputs, name="RepeatVector-1"))

model.add(TimeDistributed(Dense(1, name="dense-1")))

model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')
.....................................................................................................................
(loss: 0.4232 - val_loss: 0.5002) (CNN-2 is better than CNN-1)
.....................................................................................................................

2. LSTM Model:

model = Sequential()

model.add(LSTM(200, return_sequences=True, dropout=0.2, recurrent_dropout=0.3, input_shape=trainX.shape[-2:]))
model.add(LSTM(100, activation='relu', dropout=0.4, recurrent_dropout=0.3))
model.add(Dense(12))

3. CNN-LSTM Model:

model = Sequential()

model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=trainX.shape[-2:]))
model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(Dropout(0.2))

model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))
model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(Dropout(0.3))

model.add(Flatten())
model.add(RepeatVector(future_target))

model.add(LSTM(400, activation='relu', return_sequences=True, dropout=0.2))
model.add(TimeDistributed(Dense(1, activation='relu')))

4. ConvLSTM Model:

model = Sequential()

model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', return_sequences=True, input_shape=trainX.shape[1:]))
model.add(ConvLSTM2D(filters=128, kernel_size=(1,3), activation='relu'))

model.add(Flatten())
model.add(RepeatVector(future_outputs))

model.add(LSTM(400, activation='relu', return_sequences=True, dropout=0.2))
model.add(TimeDistributed(Dense(100, activation='relu')))
model.add(Dropout(0.4))
model.add(TimeDistributed(Dense(1)))